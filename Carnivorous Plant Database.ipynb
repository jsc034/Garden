{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run this code to create a JSON file that diables auto-quotes and auto-brackets. After executing the Python \n",
    "#command, or manually creating the file, restart your Jupyter notebook, and it should stop auto-closing quotes\n",
    "#and brackets.\n",
    "\n",
    "#from notebook.services.config import ConfigManager\n",
    "#c = ConfigManager()\n",
    "#c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})\n",
    "\n",
    "###Keyboard Shortcuts\n",
    "#Ctrl + Enter: Run single cell of code (similar to R)\n",
    "#Ctrl + Shift + Enter: Run entire notebook (similar to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intro to Web Scraping and BeautifulSoup\n",
    "#https://www.youtube.com/watch?v=XQgXKtPSzUI\n",
    "\n",
    "#exporting to excel\n",
    "#df.to_excel(\"excel_file_name.xlsx\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "#import re #for splitting strings using multiple delimiters\n",
    "import time\n",
    "import random\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When populating species_XXX variables, make sure that they are all lowercase; to make comparison easier\n",
    "#Common name on left side, taxonomy on right\n",
    "species_vft = ['venus','flytrap','flytraps','dionaea','muscipula']\n",
    "species_neps = ['tropical','asian','nepenthes']\n",
    "species_sarracenia = ['american','sarracenia']\n",
    "species_sundew = ['sundew','sundews','drosera']\n",
    "species_utric = ['bladderwort','bladderworts','utricularia']\n",
    "species_pings = ['butterwort','butterworts','pinguicula']\n",
    "species_cephs = ['australian','cephalotus']\n",
    "species_darlingtonia = ['cobra','lily','lilies','darlingtonia']\n",
    "species_heli = ['sun','heliamphora']\n",
    "#species_special = ['specimen plants','carnivero exclusives']\n",
    "\n",
    "species_all = species_vft + species_neps + species_sarracenia + species_sundew + species_utric \\\n",
    "            + species_pings + species_cephs + species_darlingtonia + species_heli\n",
    "    \n",
    "#function to check type of species\n",
    "#name is the name of the item as a string, returns a string of the type of species\n",
    "def check_species(name):\n",
    "    #cleaning: replacing special characters with spaces, all lowercase then splitting words into list\n",
    "    kind_list = name.strip().replace('(','').replace(')','').replace('[','').replace(']','').replace(',','')\n",
    "    kind_list = kind_list.lower().split(' ')\n",
    "    \n",
    "    n = len(kind_list)\n",
    "    if n == 0:\n",
    "        print('error: length of kind is 0, cannot loop')\n",
    "        return 'error'\n",
    "    \n",
    "    #will try each element in the kind list and see if it is in species_XXX\n",
    "    #if not, will keep looping over the length of n\n",
    "    for i in range(n):\n",
    "        if kind_list[i] in species_vft:\n",
    "            return 'dionaea muscipula'\n",
    "        elif kind_list[i] in species_neps:\n",
    "            return 'nepenthes'\n",
    "        elif kind_list[i] in species_sarracenia:\n",
    "            return 'sarracenia'    \n",
    "        elif kind_list[i] in species_sundew:\n",
    "            return 'drosera'\n",
    "        elif kind_list[i] in species_pings:\n",
    "            return 'pinguicula'\n",
    "        elif kind_list[i] in species_utric:\n",
    "            return 'utricularia'\n",
    "        elif kind_list[i] in species_cephs:\n",
    "            return 'cephalotus'\n",
    "        elif kind_list[i] in species_darlingtonia:\n",
    "            return 'darlingtonia'\n",
    "        elif kind_list[i] in species_heli:\n",
    "            return 'heliamphora'\n",
    "        elif i == (n-1):\n",
    "            #when list of strings are not found in species_XXX, return other\n",
    "            return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(names),len(prices),len(saleprices),len(soldouts),len(stores),len(species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>72+ Hour Heat Pack - For shipping with plants</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spagmoss 100 gram briquette</td>\n",
       "      <td>7.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...</td>\n",
       "      <td>149.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Nepenthes veitchii BE-3734 'Bario squat' (red-...</td>\n",
       "      <td>39.00</td>\n",
       "      <td></td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nepenthes aristolochioides x burkei BE-3683</td>\n",
       "      <td>16.00</td>\n",
       "      <td></td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x fusc...</td>\n",
       "      <td>24.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>Nepenthes villosa *COLLECTABLE HARD ENAMEL PIN*</td>\n",
       "      <td>8.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Nepenthes veitchii *COLLECTABLE HARD ENAMEL PIN*</td>\n",
       "      <td>8.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>Nepenthes edwardsiana *COLLECTABLE ENAMEL PIN*</td>\n",
       "      <td>8.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>Nepenthes bicalcarata *COLLECTABLE HARD ENAMEL...</td>\n",
       "      <td>8.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name   Price Sale Price  \\\n",
       "0       72+ Hour Heat Pack - For shipping with plants    4.00              \n",
       "1                         Spagmoss 100 gram briquette    7.00              \n",
       "2   Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...  149.00              \n",
       "3   Nepenthes veitchii BE-3734 'Bario squat' (red-...   39.00              \n",
       "4         Nepenthes aristolochioides x burkei BE-3683   16.00              \n",
       "..                                                ...     ...        ...   \n",
       "64  Nepenthes robcantleyi \"Queen of Hearts\" x fusc...   24.00              \n",
       "65    Nepenthes villosa *COLLECTABLE HARD ENAMEL PIN*    8.00              \n",
       "66   Nepenthes veitchii *COLLECTABLE HARD ENAMEL PIN*    8.00              \n",
       "67     Nepenthes edwardsiana *COLLECTABLE ENAMEL PIN*    8.00              \n",
       "68  Nepenthes bicalcarata *COLLECTABLE HARD ENAMEL...    8.00              \n",
       "\n",
       "    Sold Out                Store    Species  \n",
       "0             Pearl River Exotics      other  \n",
       "1             Pearl River Exotics      other  \n",
       "2             Pearl River Exotics  nepenthes  \n",
       "3   sold out  Pearl River Exotics  nepenthes  \n",
       "4   sold out  Pearl River Exotics  nepenthes  \n",
       "..       ...                  ...        ...  \n",
       "64            Pearl River Exotics  nepenthes  \n",
       "65            Pearl River Exotics  nepenthes  \n",
       "66            Pearl River Exotics  nepenthes  \n",
       "67            Pearl River Exotics  nepenthes  \n",
       "68            Pearl River Exotics  nepenthes  \n",
       "\n",
       "[69 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Pearl River Exotics\n",
    "URL = 'https://www.pearlriverexotics.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('a',attrs={'class':'site-nav__link site-nav__link--main'})\n",
    "links = links[:len(links)-1] #excluding last link \"carnivorous plants for beginners'\n",
    "\n",
    "for link in links:\n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "\n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    #finds how many pages to loop over\n",
    "    try:\n",
    "        page_count = soup.find('li',attrs={'class':'pagination__text'}).text.strip()\n",
    "        page_count = page_count[len(page_count)-1:] #grabs how many pages to loop through\n",
    "        page_count = int(page_count)\n",
    "    except (AttributeError,IndexError):\n",
    "        page_count = 1 #only 1 page\n",
    "\n",
    "    for page_number in range(page_count):\n",
    "        #wait random time between 0-5 seconds before scraping data\n",
    "        r = random.randint(0,5)\n",
    "        time.sleep(r)\n",
    "    \n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('a',attrs={'class':'grid-view-item__link'})\n",
    "\n",
    "        for container in containers:\n",
    "            name = container.find('div',attrs={'class':'h4 grid-view-item__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('span',attrs={'class':'product-price__price'}).text.strip()\n",
    "            price = price[1:] #remove the 1st character of the string '$'\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Pearl River Exotics']\n",
    "            saleprices = saleprices + [''] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!change when on sale\n",
    "            species = species + [specie]\n",
    "            \n",
    "            #looks for sold out items\n",
    "            try:\n",
    "                soldout = container.find('span',attrs={'class':'product-price__sold-out'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "        \n",
    "        #once page is scraped, grabs the URL for next page\n",
    "        try:\n",
    "            path = soup.findAll('a',attrs={'class':'btn btn--secondary btn--narrow'})\n",
    "            path = path[len(path)-1] #gets the link to the next page\n",
    "            path = path['href']\n",
    "            URL2 = URL + path\n",
    "        except (AttributeError,IndexError):\n",
    "            continue #nothing\n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Carnivorous Plant Conservation Donation</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dionaea m. 'Alien' Potted</td>\n",
       "      <td>39.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dionaea m. 'B-52' Potted</td>\n",
       "      <td>14.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dionaea m. 'Brutal Shark' Potted</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dionaea m. 'Burbank's Best' Potted</td>\n",
       "      <td>14.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>72 Hour Heat Pack</td>\n",
       "      <td>3.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>Live Sphagnum Moss</td>\n",
       "      <td>19.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>Utricularia fulva Potted</td>\n",
       "      <td>14.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>utricularia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>72 Hour Heat Pack</td>\n",
       "      <td>3.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>Utricularia livida 'Merrie Heart' Deluxe Potted</td>\n",
       "      <td>12.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>California Carnivores</td>\n",
       "      <td>utricularia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  Price Sale Price  \\\n",
       "0            Carnivorous Plant Conservation Donation   1.00              \n",
       "1                          Dionaea m. 'Alien' Potted  39.99              \n",
       "2                           Dionaea m. 'B-52' Potted  14.99              \n",
       "3                   Dionaea m. 'Brutal Shark' Potted  29.99              \n",
       "4                 Dionaea m. 'Burbank's Best' Potted  14.99              \n",
       "..                                               ...    ...        ...   \n",
       "127                                72 Hour Heat Pack   3.99              \n",
       "128                               Live Sphagnum Moss  19.99              \n",
       "129                         Utricularia fulva Potted  14.99              \n",
       "130                                72 Hour Heat Pack   3.99              \n",
       "131  Utricularia livida 'Merrie Heart' Deluxe Potted  12.99              \n",
       "\n",
       "    Sold Out                  Store            Species  \n",
       "0             California Carnivores              other  \n",
       "1             California Carnivores  dionaea muscipula  \n",
       "2             California Carnivores  dionaea muscipula  \n",
       "3             California Carnivores  dionaea muscipula  \n",
       "4             California Carnivores  dionaea muscipula  \n",
       "..       ...                    ...                ...  \n",
       "127           California Carnivores              other  \n",
       "128           California Carnivores              other  \n",
       "129           California Carnivores        utricularia  \n",
       "130           California Carnivores              other  \n",
       "131           California Carnivores        utricularia  \n",
       "\n",
       "[132 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#California Carnivores\n",
    "URL = 'https://www.californiacarnivores.com/'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "soup = soup.find('ul',attrs={'class':'sidebar-module__list'})\n",
    "links = soup.findAll('a')\n",
    "links = [links[i] for i in range(len(links)) if i not in (0,1,3,13,16,22,26,30,31,32,33,34,35,36,37)]\n",
    "#exluding following pages: plant collections (0), easy to grow (1), drosera (3), sarracenia (13),\n",
    "#nepenthes (16), pinguicula (22), utricularia (26), waterwheel, ..., gifts (30-37)\n",
    "\n",
    "for link in links:\n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half'})\n",
    "        containers_sale = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half on-sale'})\n",
    "\n",
    "        #grabs information of normal items\n",
    "        for container in containers:\n",
    "            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip()\n",
    "            separate_index = price.find('$') #look for 1st instance of $\n",
    "            price = price[separate_index+2:] #remove the all characters before and including the string '$ '\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            saleprices = saleprices + ['']\n",
    "            stores = stores + ['California Carnivores']\n",
    "            soldouts = soldouts + ['']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #grabs information of sale items\n",
    "        for container in containers_sale:\n",
    "            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip() #price of items on sale should be of form '$ xx.xx\\n$ xx.xx'\n",
    "            separate_index = price.rfind('$') #from end of string, look for 1st instance of $\n",
    "            price_before = price[separate_index:] #gets original price\n",
    "            price_before = price_before[2:] #remove the first 2 characters of the string '$ '\n",
    "            price_after = price[:separate_index] #gets sale price\n",
    "            price_after = price_after[2:] #remove the first 2 characters of the string '$ '\n",
    "            price_after = price_after[:-1] #remove the last 2 characters of the string '$ '\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price_before]\n",
    "            saleprices = saleprices + [price_after]\n",
    "            stores = stores + ['California Carnivores']\n",
    "            soldouts = soldouts + ['']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            path = soup.find('a',attrs={'title':'Next »'})\n",
    "            path = path['href']\n",
    "            URL2 = URL + path\n",
    "        except TypeError:\n",
    "            page_next = False\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Darlingtonia Californica Cobra Lily unpotted s...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>darlingtonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Darlingtonia Californica Cobra Lily unpotted n...</td>\n",
       "      <td>28.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>darlingtonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>drosera scorpiodes unpotted near flowering siz...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cephalotus follicularis Charles Brewer potted ...</td>\n",
       "      <td>45.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>cephalotus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>venus flytrap bigmouth unpotted 2-3 year old s...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>Nepenthes burbidgeae seed grown unpotted 4+ in...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>Nepenthes klossii unpotted 2-3 inch leafspan p...</td>\n",
       "      <td>400.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>Nepenthes klossii unpotted 4+ inch leafspan plant</td>\n",
       "      <td>500.00</td>\n",
       "      <td>375.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>Nepenthes spectabilis large form seed grown un...</td>\n",
       "      <td>45.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>Nepenthes longifolia unpotted 6+ inch leafspan...</td>\n",
       "      <td>80.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td></td>\n",
       "      <td>Cook's Carnivorous Plants</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name   Price Sale Price  \\\n",
       "0    Darlingtonia Californica Cobra Lily unpotted s...   17.00      12.00   \n",
       "1    Darlingtonia Californica Cobra Lily unpotted n...   28.00      20.00   \n",
       "2    drosera scorpiodes unpotted near flowering siz...    5.00       3.25   \n",
       "3    Cephalotus follicularis Charles Brewer potted ...   45.00      25.00   \n",
       "4    venus flytrap bigmouth unpotted 2-3 year old s...   10.00       7.00   \n",
       "..                                                 ...     ...        ...   \n",
       "100  Nepenthes burbidgeae seed grown unpotted 4+ in...   60.00      40.00   \n",
       "101  Nepenthes klossii unpotted 2-3 inch leafspan p...  400.00     275.00   \n",
       "102  Nepenthes klossii unpotted 4+ inch leafspan plant  500.00     375.00   \n",
       "103  Nepenthes spectabilis large form seed grown un...   45.00      35.00   \n",
       "104  Nepenthes longifolia unpotted 6+ inch leafspan...   80.00      65.00   \n",
       "\n",
       "    Sold Out                      Store            Species  \n",
       "0             Cook's Carnivorous Plants       darlingtonia  \n",
       "1             Cook's Carnivorous Plants       darlingtonia  \n",
       "2             Cook's Carnivorous Plants            drosera  \n",
       "3             Cook's Carnivorous Plants         cephalotus  \n",
       "4             Cook's Carnivorous Plants  dionaea muscipula  \n",
       "..       ...                        ...                ...  \n",
       "100           Cook's Carnivorous Plants          nepenthes  \n",
       "101           Cook's Carnivorous Plants          nepenthes  \n",
       "102           Cook's Carnivorous Plants          nepenthes  \n",
       "103           Cook's Carnivorous Plants          nepenthes  \n",
       "104           Cook's Carnivorous Plants          nepenthes  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Cook's Carnivorous Plants\n",
    "URL = 'http://www.flytraps.com/Scripts/'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('span',attrs={'class':'CPcatDescProd'})\n",
    "links = links[:22] #from cobra lily to nepenthes hybrid lowland\n",
    "\n",
    "for link in links:\n",
    "    #Checks what type of species\n",
    "    kind = link.text\n",
    "    specie = check_species(kind)\n",
    "        \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.a['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    containers = soup.findAll('div',attrs={'class':'prod-classic'})\n",
    "    containers_count = len(containers)\n",
    "    \n",
    "    #print(URL2)\n",
    "    #If is not blank, scrapes info. otherwise skips page\n",
    "    if containers_count != 0:\n",
    "        \n",
    "        #each page contains 15 items, goes to next page when page_next mod 15 == 0\n",
    "        page_next = 0\n",
    "        while page_next % 15 == 0:\n",
    "            page = urlopen(URL2)\n",
    "            soup = BeautifulSoup(page,'html.parser')\n",
    "            containers = soup.findAll('div',attrs={'class':'prod-classic'})\n",
    "    \n",
    "            for container in containers:\n",
    "                name = container.h3.text.strip()\n",
    "            \n",
    "                #Most items on site are on sale. Try to process items as if the were on sale. If not on sale, then exception\n",
    "                try:\n",
    "                    price = container.find('del',attrs={'class':'CPprodLPriceV'}).text.strip()\n",
    "                    price = price[1:] #removed '$' at beginning\n",
    "            \n",
    "                    saleprice = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    separate_index = saleprice.find('$') #look for 1st instance of $\n",
    "                    saleprice = saleprice[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                    saleprice = saleprice[:-3] #remove ' ea' from end of sales price\n",
    "                except AttributeError:\n",
    "                    price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    separate_index = price.find('$') #look for 1st instance of $\n",
    "                    price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                    price = price[:-3] #remove ' ea' from end of sales price\n",
    "                \n",
    "                    saleprice = ''\n",
    "            \n",
    "                names = names + [name]\n",
    "                prices = prices + [price]\n",
    "                stores = stores + ['Cook\\'s Carnivorous Plants']\n",
    "                soldouts = soldouts + ['']\n",
    "                species = species + [specie]\n",
    "                saleprices = saleprices + [saleprice]\n",
    "                page_next = page_next + 1\n",
    "                \n",
    "            #Updates the URL for next page; stops the while loop if there is no next page\n",
    "            if page_next % 15 == 0:\n",
    "                paths = soup.find('div',attrs={'class':'spacing fl-right'})\n",
    "                paths = paths.findAll('a')\n",
    "                path = paths[len(paths)-1]['href'] #href of the last link (should be next page)\n",
    "                URL2 = URL + path\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Nepenthes veitchii H/L x burbidgeae</td>\n",
       "      <td>149.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nepenthes ventricosa x ovata - DM033</td>\n",
       "      <td>49.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Nepenthes pectinata x ventricosa</td>\n",
       "      <td>39.99</td>\n",
       "      <td></td>\n",
       "      <td>sold out</td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Nepenthes 'Splendid Diana' x ventricosa red, C...</td>\n",
       "      <td>24.99</td>\n",
       "      <td></td>\n",
       "      <td>sold out</td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nepenthes ampullaria x veitchii, BE-3720</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td>sold out</td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>Drosera fulva</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>Drosera darwinensis</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>Drosera aff. dilato-petiolaris</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>Drosera broomensis</td>\n",
       "      <td>29.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>Drosera caduca</td>\n",
       "      <td>24.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Carnivero</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name   Price Sale Price  \\\n",
       "0                  Nepenthes veitchii H/L x burbidgeae  149.99              \n",
       "1                 Nepenthes ventricosa x ovata - DM033   49.99              \n",
       "2                     Nepenthes pectinata x ventricosa   39.99              \n",
       "3    Nepenthes 'Splendid Diana' x ventricosa red, C...   24.99              \n",
       "4             Nepenthes ampullaria x veitchii, BE-3720   29.99              \n",
       "..                                                 ...     ...        ...   \n",
       "386                                      Drosera fulva   29.99              \n",
       "387                                Drosera darwinensis   29.99              \n",
       "388                     Drosera aff. dilato-petiolaris   29.99              \n",
       "389                                 Drosera broomensis   29.99              \n",
       "390                                     Drosera caduca   24.99              \n",
       "\n",
       "     Sold Out      Store    Species  \n",
       "0              Carnivero  nepenthes  \n",
       "1              Carnivero  nepenthes  \n",
       "2    sold out  Carnivero  nepenthes  \n",
       "3    sold out  Carnivero  nepenthes  \n",
       "4    sold out  Carnivero  nepenthes  \n",
       "..        ...        ...        ...  \n",
       "386            Carnivero    drosera  \n",
       "387            Carnivero    drosera  \n",
       "388            Carnivero    drosera  \n",
       "389            Carnivero    drosera  \n",
       "390            Carnivero    drosera  \n",
       "\n",
       "[391 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Carnivero\n",
    "URL = 'https://www.carnivero.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('div',attrs={'class':'grid__item small--one-half medium-up--one-fifth slide-up-animation animated'})\n",
    "links = [links[i] for i in range(10) if i!=1]  #all categories except beginner plants\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:            \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.a['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "  \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('div',attrs={'class':'product grid__item medium-up--one-third small--one-half slide-up-animation animated'})\n",
    "    \n",
    "        for container in containers:\n",
    "            name = container.find('div',attrs={'class':'product__title text-center'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            try:\n",
    "                price = container.find('span',attrs={'class':'product__price'}).text.strip()\n",
    "                separate_index = price.find('$') #look for 1st instance of $\n",
    "                price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                prices = prices + [price]\n",
    "                saleprices = saleprices + ['']           \n",
    "            except AttributeError:\n",
    "                #grab original price\n",
    "                price = container.find('s').text.strip()\n",
    "                separate_index = price.find('$') #look for 1st instance of $\n",
    "                price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                prices = prices + [price]\n",
    "            \n",
    "                #grab new sales price\n",
    "                price = container.find('span',attrs={'class':'product__price--on-sale'}).text.strip()\n",
    "                separate_index = price.find('$') #look for 1st instance of $\n",
    "                price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                saleprices = saleprices + [price] \n",
    "            \n",
    "            try:\n",
    "                soldout = container.find('strong',attrs={'class':'sold-out-text'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "            \n",
    "            names = names + [name]\n",
    "            stores = stores + ['Carnivero']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            path = soup.find('span',attrs={'class':'next'})\n",
    "            path = path.a['href']\n",
    "            URL2 = 'https://www.carnivero.com' + path\n",
    "        except AttributeError:\n",
    "            page_next = False\n",
    "        \n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Native Exotics\n",
    "URL = 'https://nativeexoticsonline.com'\n",
    "h = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "req = Request(URL,headers=h) \n",
    "page = urlopen(req).read() \n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.find('ul',attrs={'class':'dropdown'})\n",
    "links = links.findAll('a')\n",
    "pages_of_interest = [5] + list(range(10,15)) #All Neps + Cephs,Drosera,..., Utrics\n",
    "links = [links[i] for i in pages_of_interest]\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:      \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        req = Request(URL2,headers=h) \n",
    "        page = urlopen(req).read() \n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        container_big = soup.find('ul',attrs={'class':'products columns-4'})\n",
    "        containers = container_big.findAll('li')\n",
    "    \n",
    "        for container in containers:\n",
    "            name = container.find('h2').text.strip()\n",
    "            specie = check_species(name)\n",
    "        \n",
    "            price_list = container.findAll('span',attrs={'class':'woocommerce-Price-amount amount'})\n",
    "            #2 prices listed when on sale. 1st list element is original price, 2nd element is sales price\n",
    "            if len(price_list) == 2:\n",
    "                price = price_list[0].text.strip()\n",
    "                price = price[2:]\n",
    "                saleprice = price_list[1].text.strip()\n",
    "                saleprice = saleprice[2:]             \n",
    "            elif len(price_list) == 1:\n",
    "                price = price_list[0].text.strip()\n",
    "                price = price[2:]\n",
    "                saleprice = ''\n",
    "        \n",
    "            try:\n",
    "                soldout = container.find('span',attrs={'class':'soldout'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "            \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Native Exotics']\n",
    "            saleprices = saleprices + [saleprice]\n",
    "            species = species + [specie]\n",
    "            \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            URL2 = soup.find('a',attrs={'class':'next page-numbers'})\n",
    "            URL2 = URL2['href']\n",
    "        except TypeError:\n",
    "            page_next = False\n",
    "        \n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Carnivorous Plant Nursery\n",
    "URL = 'https://carnivorousplantnursery.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('article')\n",
    "links = links[:9] #Only looks at VFT to buterworts\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:      \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.find('figure')\n",
    "    path = path.a['href']\n",
    "    URL2 = URL + path   \n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    containers = soup.findAll('article',attrs={'class':'productgrid--item imagestyle--cropped-small '})\n",
    "    for container in containers:\n",
    "        name = container.find('h2').text.strip()\n",
    "        specie = check_species(name)\n",
    "    \n",
    "        price = container.find('div',attrs={'class':'price--main'}).text.strip()\n",
    "        separate_index = price.find('$') #look for 1st instance of $\n",
    "        price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "    \n",
    "        names = names + [name]\n",
    "        prices = prices + [price]\n",
    "        stores = stores + ['Carnivorous Plant Nursery']\n",
    "        saleprices = saleprices + [''] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!change when on sale\n",
    "        species = species + [specie]\n",
    "        \n",
    "        #looks for sold out items\n",
    "        try:\n",
    "            soldout = container.find('span',attrs={'class':'productitem--badge badge--soldout'}).text.strip()\n",
    "            soldouts = soldouts + [soldout.lower()]\n",
    "        except AttributeError:\n",
    "            soldouts = soldouts + ['']\n",
    "            \n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>72 Hour Heat Pack</td>\n",
       "      <td>3.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Akai Ryu Venus Fly Trap</td>\n",
       "      <td>12.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Bugout™</td>\n",
       "      <td>35.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cape Sundew Drosera capensis</td>\n",
       "      <td>12.00</td>\n",
       "      <td></td>\n",
       "      <td>out of stock</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fraser Island Sundew Drosera spatulata</td>\n",
       "      <td>8.00</td>\n",
       "      <td></td>\n",
       "      <td>out of stock</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>drosera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>Nepenthes singalana x (burbidgeae x edwardsian...</td>\n",
       "      <td>40.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>Nepenthes singalana x burkei BE 3878</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>Nepenthes singalana x hamata BE3955</td>\n",
       "      <td>50.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>Nepenthes singalana x mirabilis var. globosa B...</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>Nepenthes singalana x robcantleyi BE3959</td>\n",
       "      <td>40.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  Price Sale Price  \\\n",
       "0                                    72 Hour Heat Pack   3.00              \n",
       "1                              Akai Ryu Venus Fly Trap  12.00              \n",
       "2                                              Bugout™  35.00              \n",
       "3                         Cape Sundew Drosera capensis  12.00              \n",
       "4               Fraser Island Sundew Drosera spatulata   8.00              \n",
       "..                                                 ...    ...        ...   \n",
       "155  Nepenthes singalana x (burbidgeae x edwardsian...  40.00              \n",
       "156               Nepenthes singalana x burkei BE 3878  20.00              \n",
       "157                Nepenthes singalana x hamata BE3955  50.00              \n",
       "158  Nepenthes singalana x mirabilis var. globosa B...  20.00              \n",
       "159           Nepenthes singalana x robcantleyi BE3959  40.00              \n",
       "\n",
       "         Sold Out                 Store            Species  \n",
       "0                  Bergen Water Gardens              other  \n",
       "1                  Bergen Water Gardens  dionaea muscipula  \n",
       "2                  Bergen Water Gardens              other  \n",
       "3    out of stock  Bergen Water Gardens            drosera  \n",
       "4    out of stock  Bergen Water Gardens            drosera  \n",
       "..            ...                   ...                ...  \n",
       "155                Bergen Water Gardens          nepenthes  \n",
       "156                Bergen Water Gardens          nepenthes  \n",
       "157                Bergen Water Gardens          nepenthes  \n",
       "158                Bergen Water Gardens          nepenthes  \n",
       "159                Bergen Water Gardens          nepenthes  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Bergen Water Gardens\n",
    "#cannot extract next page button functionality; cannot extract how many pages total\n",
    "#instead keeps going to next page until error\n",
    "try:\n",
    "    page_number = 1\n",
    "    while page_number < 11:\n",
    "        URL = 'https://bergenwatergardens.com/product-category/carnivorous-plants/?fwp_paged=%d' % page_number\n",
    "        h = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "        req = Request(URL,headers=h) \n",
    "        page = urlopen(req).read() \n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "    \n",
    "        #wait random time between 0-5 seconds before scraping data\n",
    "        r = random.randint(0,5)\n",
    "        time.sleep(r)\n",
    "        \n",
    "        containers = soup.find('ul',attrs={'class':'products columns-4'})\n",
    "        containers = containers.findAll('li')        \n",
    "        \n",
    "        for container in containers:\n",
    "            name = container.find('h2').text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "            #if item is on sale, gets normal price and sale price\n",
    "            try:\n",
    "                container.find('span',attrs={'class':'onsale'}).text.strip() == 'Sale!'\n",
    "    \n",
    "                separate_index = price.find('$') #from BEGINNING of string, look for 1st instance of $\n",
    "                price_before = price[separate_index:] #gets original price\n",
    "                price_before = price_before[1:7] #remove everything except price\n",
    "        \n",
    "                separate_index = price.rfind('$') #from END of string, look for 1st instance of $\n",
    "                price_after = price[separate_index:] #gets original price\n",
    "                price_after = price_after[1:7] #remove everything except price\n",
    "    \n",
    "                price = price_before\n",
    "                saleprice = price_after\n",
    "            #else just get the normal price\n",
    "            except AttributeError:\n",
    "                price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                price = price[2:] #removes '$ ' before price\n",
    "                saleprice = ''\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Bergen Water Gardens']\n",
    "            saleprices = saleprices + [saleprice]\n",
    "            species = species + [specie]        \n",
    "        \n",
    "            #looks for sold out items\n",
    "            try:\n",
    "                URL2 = container.a['href']\n",
    "                req = Request(URL2,headers=h) \n",
    "                page = urlopen(req).read() \n",
    "                soup = BeautifulSoup(page,'html.parser')\n",
    "                \n",
    "                soldout = soup.find('p',attrs={'class':'stock out-of-stock'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "                        \n",
    "        #increase page_number for while loop\n",
    "        page_number = page_number + 1\n",
    "#if container is empty, pass- does nothing, 'pass' in python instead of 'continue'\n",
    "except (AttributeError,IndexError):\n",
    "    pass \n",
    "    \n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-24a3fa2d6230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Petflytrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.petflytrap.com/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []\n",
    "\n",
    "#Petflytrap\n",
    "URL = 'https://www.petflytrap.com/'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "soup = soup.find('table')\n",
    "links = soup.findAll('td',attrs={'style':'text-indent:45px;'})\n",
    "links = [links[i] for i in range(len(links)) if i not in (0,3,10,11,12)]\n",
    "#exluding following pages: All carnivorous plants (0), tropical pitcher plants (3)\n",
    "#which is a duplicate of nepenthes (4), terrariums & kits (10-12)s\n",
    "\n",
    "for link in links:\n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.a['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = containers = soup.findAll('td',attrs={'width':'20%'})\n",
    "        \n",
    "        #if there are no items on the page, skips page\n",
    "        if len(containers) == 0:\n",
    "            break\n",
    "        #else grabs information of normal items\n",
    "        else:\n",
    "            for container in containers:\n",
    "                #try processing container info\n",
    "                try:\n",
    "                    name = container.text\n",
    "                    separate_index = name.rfind('Y') #finds the index for 'Y' to remove everything after 'Your Price...'\n",
    "                    separate_index\n",
    "                    name = name[:separate_index] #removes all text after 'Your Price'\n",
    "                    name = name[6:-4] #removes all newlines before and after name\n",
    "                    specie = check_species(name)\n",
    "\n",
    "                    price = container.find('td',attrs={'class':'price-info'}).text.strip()\n",
    "                    #if item is on sale, seperate into price_before and price_after\n",
    "                    if 'On sale' in price:\n",
    "                        separate_index = price.find('$') #from BEGINNING of string, look for 1st instance of $\n",
    "                        price_before = price[separate_index:] #gets original price\n",
    "                        price_before = price_before[1:6] #remove everything except price\n",
    "        \n",
    "                        separate_index = price.rfind('$') #from END of string, look for 1st instance of $\n",
    "                        price_after = price[separate_index:] #gets original price\n",
    "                        price_after = price_after[1:6] #remove everything except price\n",
    "                    else:\n",
    "                        separate_index = price.rfind('$') #from end of string, look for 1st instance of $\n",
    "                        price_before = price[separate_index:] #gets original price\n",
    "                        price_before = price_before[1:] #remove the first 2 characters of the string '$ '\n",
    "                        price_after = ''\n",
    "    \n",
    "                    names = names + [name]\n",
    "                    prices = prices + [price_before]\n",
    "                    saleprices = saleprices + [price_after]\n",
    "                    stores = stores + ['Petflytap']\n",
    "                    soldouts = soldouts + ['']\n",
    "                    species = species + [specie]\n",
    "                #if container is empty, pass- does nothing, 'pass' in python instead of 'continue'\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        \n",
    "            #Updates the URL for next page; stops the while loop if there is no next page\n",
    "            try:\n",
    "                path = soup.findAll('font',attrs={'size':'1'})\n",
    "                path = path[len(path)-1].a['href']\n",
    "                URL2 = URL + path\n",
    "            except (TypeError,IndexError):\n",
    "                page_next = False\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export concatinated df to Excel\n",
    "df.to_excel(\"df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>72+ Hour Heat Pack - For shipping with plants</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spagmoss 100 gram briquette</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Nepenthes veitchii BE-3734 'Bario squat' (red-...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nepenthes aristolochioides x burkei BE-3683</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2131</td>\n",
       "      <td>Nepenthes singalana x (burbidgeae x edwardsian...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2132</td>\n",
       "      <td>Nepenthes singalana x burkei BE 3878</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2133</td>\n",
       "      <td>Nepenthes singalana x hamata BE3955</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2134</td>\n",
       "      <td>Nepenthes singalana x mirabilis var. globosa B...</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2135</td>\n",
       "      <td>Nepenthes singalana x robcantleyi BE3959</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bergen Water Gardens</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name   Price Sale Price  \\\n",
       "0         72+ Hour Heat Pack - For shipping with plants    4.00        NaN   \n",
       "1                           Spagmoss 100 gram briquette    7.00        NaN   \n",
       "2     Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...  149.00        NaN   \n",
       "3     Nepenthes veitchii BE-3734 'Bario squat' (red-...   39.00        NaN   \n",
       "4           Nepenthes aristolochioides x burkei BE-3683   16.00        NaN   \n",
       "...                                                 ...     ...        ...   \n",
       "2131  Nepenthes singalana x (burbidgeae x edwardsian...   40.00        NaN   \n",
       "2132               Nepenthes singalana x burkei BE 3878   20.00        NaN   \n",
       "2133                Nepenthes singalana x hamata BE3955   50.00        NaN   \n",
       "2134  Nepenthes singalana x mirabilis var. globosa B...   20.00        NaN   \n",
       "2135           Nepenthes singalana x robcantleyi BE3959   40.00        NaN   \n",
       "\n",
       "      Sold Out                 Store    Species  \n",
       "0          NaN   Pearl River Exotics      other  \n",
       "1          NaN   Pearl River Exotics      other  \n",
       "2          NaN   Pearl River Exotics  nepenthes  \n",
       "3     sold out   Pearl River Exotics  nepenthes  \n",
       "4     sold out   Pearl River Exotics  nepenthes  \n",
       "...        ...                   ...        ...  \n",
       "2131       NaN  Bergen Water Gardens  nepenthes  \n",
       "2132       NaN  Bergen Water Gardens  nepenthes  \n",
       "2133       NaN  Bergen Water Gardens  nepenthes  \n",
       "2134       NaN  Bergen Water Gardens  nepenthes  \n",
       "2135       NaN  Bergen Water Gardens  nepenthes  \n",
       "\n",
       "[2136 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting exported df back into correct format\n",
    "df = pd.read_excel('df_2020_02_05.xlsx')\n",
    "df = df.drop(columns='Unnamed: 0') #removing column of indecies\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Once the complete database is compiled, apply tagging function - tags any species found in product\n",
    "#https://www.carnivorousplants.co.uk/resources/nepenthes-interactive-guide/\n",
    "#https://en.wikipedia.org/wiki/List_of_Nepenthes_species\n",
    "\n",
    "#compare product to database of species known\n",
    "#if str in database, then species = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 172\n",
    "name_nepenthes = [''] * n\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Nepenthes_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('tr')\n",
    "\n",
    "for i in range(1,n):\n",
    "    container = containers[i]\n",
    "    name = container.find('a')\n",
    "    name_nepenthes[i] = name['title'][10:] #removing 'Nepenthes ' from string\n",
    "    \n",
    "name_nepenthes = name_nepenthes[1:] #remove header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "name_nepenthes = [''] * n\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Nepenthes_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('tr')\n",
    "\n",
    "for i in range(1,n):\n",
    "    container = containers[i]\n",
    "    name = container.find('a')\n",
    "    name_nepenthes[i] = name['title'][10:] #removing 'Nepenthes ' from string\n",
    "    \n",
    "name_nepenthes = name_nepenthes[1:] #remove header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Cross1'] = ''\n",
    "df['Cross2'] = ''\n",
    "df['Cross3'] = ''\n",
    "df['Cross4'] = ''\n",
    "df['Cross5'] = ''\n",
    "df['Cross6'] = ''\n",
    "\n",
    "#i is row index, j is column index\n",
    "#len(df) gives number of rows in df\n",
    "for i in range(len(df)):\n",
    "    string_split = df.at[i,'Name'].replace('(','').replace(')','').replace('[','').replace(']','').replace(',','')\n",
    "    #removing all of the special characters:()[] so the string is split into 'ventricosa' and not '(ventricosa''\n",
    "    string_split = string_split.split(' ')\n",
    "    count = 1                           #counter for column name\n",
    "    for j in range(len(string_split)):\n",
    "        if string_split[j] in name_nepenthes:\n",
    "            column = 'Cross%d' % count\n",
    "            count = count + 1\n",
    "            df.loc[[i],[column]] = string_split[j]\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "#also consider the cases for natural/common hybrids: ventrata, miranda\n",
    "#create special if clause when tag is not found, open product page and scan description text for tags\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check what does not have any Cross1 tag\n",
    "for i in range(len(df)):\n",
    "    if df.at[i,'Cross1'] is '':\n",
    "        print(df.at[i,'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
