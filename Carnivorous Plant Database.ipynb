{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run this code to create a JSON file that diables auto-quotes and auto-brackets. After executing the Python \n",
    "#command, or manually creating the file, restart your Jupyter notebook, and it should stop auto-closing quotes\n",
    "#and brackets.\n",
    "\n",
    "#from notebook.services.config import ConfigManager\n",
    "#c = ConfigManager()\n",
    "#c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})\n",
    "\n",
    "###Keyboard Shortcuts\n",
    "#Ctrl + Enter: Run single cell of code (similar to R)\n",
    "#Ctrl + Shift + Enter: Run entire notebook (similar to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intro to Web Scraping and BeautifulSoup\n",
    "#https://www.youtube.com/watch?v=XQgXKtPSzUI\n",
    "\n",
    "#Beautiful Soup HTTP Error 403\n",
    "#URL = 'https://www.petflytrap.com/All-carnivorous-plants_c_11-%d-3.html' % page_number\n",
    "#h = {'User-Agent':'Mozilla/5.0'}\n",
    "#req = Request(URL,headers=h) \n",
    "#page = urlopen(req).read()\n",
    "#soup = BeautifulSoup(page,'html.parser')\n",
    "\n",
    "#exporting to excel\n",
    "#df.to_excel(\"excel_file_name.xlsx\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "#import re #for splitting strings using multiple delimiters\n",
    "import time\n",
    "import random\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "saleprices = []\n",
    "soldouts = []\n",
    "stores = []\n",
    "species = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When populating species_XXX variables, make sure that they are all lowercase; to make comparison easier\n",
    "#Common name on left side, taxonomy on right\n",
    "species_vft = ['venus','flytrap','flytraps','dionaea','muscipula']\n",
    "species_neps = ['tropical','asian','nepenthes','N.']\n",
    "species_sarracenia = ['american','sarracenia']\n",
    "species_sundew = ['sundew','sundews','drosera']\n",
    "species_utric = ['bladderwort','bladderworts','utricularia']\n",
    "species_pings = ['butterwort','butterworts','pinguicula']\n",
    "species_cephs = ['australian','cephalotus']\n",
    "species_darlingtonia = ['cobra','lily','lilies','darlingtonia']\n",
    "species_heli = ['sun','heliamphora']\n",
    "#species_special = ['specimen plants','carnivero exclusives']\n",
    "\n",
    "species_all = species_vft + species_neps + species_sarracenia + species_sundew + species_utric \\\n",
    "            + species_pings + species_cephs + species_darlingtonia + species_heli\n",
    "    \n",
    "#function to check type of species\n",
    "#name is the name of the item as a string, returns a string of the type of species\n",
    "def check_species(name):\n",
    "    #cleaning: replacing special characters with spaces, all lowercase then splitting words into list\n",
    "    kind_list = name.strip().replace('(','').replace(')','').replace('[','').replace(']','').replace(',','')\n",
    "    kind_list = kind_list.lower().split(' ')\n",
    "    \n",
    "    n = len(kind_list)\n",
    "    if n == 0:\n",
    "        print('error: length of kind is 0, cannot loop')\n",
    "        return 'error'\n",
    "    \n",
    "    #will try each element in the kind list and see if it is in species_XXX\n",
    "    #if not, will keep looping over the length of n\n",
    "    for i in range(n):\n",
    "        if kind_list[i] in species_vft:\n",
    "            return 'dionaea muscipula'\n",
    "        elif kind_list[i] in species_neps:\n",
    "            return 'nepenthes'\n",
    "        elif kind_list[i] in species_sarracenia:\n",
    "            return 'sarracenia'    \n",
    "        elif kind_list[i] in species_sundew:\n",
    "            return 'drosera'\n",
    "        elif kind_list[i] in species_pings:\n",
    "            return 'pinguicula'\n",
    "        elif kind_list[i] in species_utric:\n",
    "            return 'utricularia'\n",
    "        elif kind_list[i] in species_cephs:\n",
    "            return 'cephalotus'\n",
    "        elif kind_list[i] in species_darlingtonia:\n",
    "            return 'darlingtonia'\n",
    "        elif kind_list[i] in species_heli:\n",
    "            return 'heliamphora'\n",
    "        elif i == (n-1):\n",
    "            #when list of strings are not found in species_XXX, return other\n",
    "            return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(names),len(prices),len(saleprices),len(soldouts),len(stores),len(species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked 3/28/20\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Pearl River Exotics\\nURL = 'https://www.pearlriverexotics.com'\\npage = urlopen(URL)\\nsoup = BeautifulSoup(page,'html.parser')\\nlinks = soup.findAll('a',attrs={'class':'site-nav__link site-nav__link--main'})\\nlinks = links[:len(links)-5] #excluding last sections 'carnivorous plants for beginners' to 'shipping policy'\\n\\nfor link in links:\\n    #Create URL2 to be URL of species type\\n    path = link['href']\\n    URL2 = URL + path\\n\\n    page = urlopen(URL2)\\n    soup = BeautifulSoup(page,'html.parser')\\n    #finds how many pages to loop over\\n    try:\\n        page_count = soup.find('li',attrs={'class':'pagination__text'}).text.strip()\\n        page_count = page_count[len(page_count)-1:] #grabs how many pages to loop through\\n        page_count = int(page_count)\\n    except (AttributeError,IndexError):\\n        page_count = 1 #only 1 page\\n\\n    for page_number in range(page_count):\\n        #wait random time between 0-5 seconds before scraping data\\n        r = random.randint(0,5)\\n        time.sleep(r)\\n    \\n        page = urlopen(URL2)\\n        soup = BeautifulSoup(page,'html.parser')\\n        containers = soup.findAll('a',attrs={'class':'grid-view-item__link'})\\n\\n        for container in containers:\\n            name = container.find('div',attrs={'class':'h4 grid-view-item__title'}).text.strip()\\n            specie = check_species(name)\\n\\n            price = container.find('span',attrs={'class':'product-price__price'}).text.strip()\\n            #if sale is in price text, get price and sale price\\n            if 'Sale' in price:\\n                separate_index = price.find('\\n') #from BEGINNING of string, look for 1st instance of '\\n'\\n                saleprice = price[1:separate_index]\\n                \\n                price = container.find('s',attrs={'class':'product-price__price'}).text.strip()\\n                price = price[1:]\\n            else:\\n                price = price[1:] #remove the 1st character of the string '$'\\n                saleprice = ''\\n    \\n            names = names + [name]\\n            prices = prices + [price]\\n            stores = stores + ['Pearl River Exotics']\\n            saleprices = saleprices + [saleprice]\\n            species = species + [specie]\\n            \\n            #looks for sold out items\\n            try:\\n                soldout = container.find('span',attrs={'class':'product-price__sold-out'}).text.strip()\\n                soldouts = soldouts + [soldout.lower()]\\n            except AttributeError:\\n                soldouts = soldouts + ['']\\n        \\n        #once page is scraped, grabs the URL for next page\\n        try:\\n            path = soup.findAll('a',attrs={'class':'btn btn--secondary btn--narrow'})\\n            path = path[len(path)-1] #gets the link to the next page\\n            path = path['href']\\n            URL2 = URL + path\\n        except (AttributeError,IndexError):\\n            continue #nothing\\n\\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf = pd.DataFrame(d)\\ndf\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked 3/28/20\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Pearl River Exotics\n",
    "URL = 'https://www.pearlriverexotics.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('a',attrs={'class':'site-nav__link site-nav__link--main'})\n",
    "links = links[:len(links)-5] #excluding last sections 'carnivorous plants for beginners' to 'shipping policy'\n",
    "\n",
    "for link in links:\n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "\n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    #finds how many pages to loop over\n",
    "    try:\n",
    "        page_count = soup.find('li',attrs={'class':'pagination__text'}).text.strip()\n",
    "        page_count = page_count[len(page_count)-1:] #grabs how many pages to loop through\n",
    "        page_count = int(page_count)\n",
    "    except (AttributeError,IndexError):\n",
    "        page_count = 1 #only 1 page\n",
    "\n",
    "    for page_number in range(page_count):\n",
    "        #wait random time between 0-5 seconds before scraping data\n",
    "        r = random.randint(0,5)\n",
    "        time.sleep(r)\n",
    "    \n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('a',attrs={'class':'grid-view-item__link'})\n",
    "\n",
    "        for container in containers:\n",
    "            name = container.find('div',attrs={'class':'h4 grid-view-item__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('span',attrs={'class':'product-price__price'}).text.strip()\n",
    "            #if sale is in price text, get price and sale price\n",
    "            if 'Sale' in price:\n",
    "                separate_index = price.find('\\n') #from BEGINNING of string, look for 1st instance of '\\n'\n",
    "                saleprice = price[1:separate_index]\n",
    "                \n",
    "                price = container.find('s',attrs={'class':'product-price__price'}).text.strip()\n",
    "                price = price[1:]\n",
    "            else:\n",
    "                price = price[1:] #remove the 1st character of the string '$'\n",
    "                saleprice = ''\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Pearl River Exotics']\n",
    "            saleprices = saleprices + [saleprice]\n",
    "            species = species + [specie]\n",
    "            \n",
    "            #looks for sold out items\n",
    "            try:\n",
    "                soldout = container.find('span',attrs={'class':'product-price__sold-out'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "        \n",
    "        #once page is scraped, grabs the URL for next page\n",
    "        try:\n",
    "            path = soup.findAll('a',attrs={'class':'btn btn--secondary btn--narrow'})\n",
    "            path = path[len(path)-1] #gets the link to the next page\n",
    "            path = path['href']\n",
    "            URL2 = URL + path\n",
    "        except (AttributeError,IndexError):\n",
    "            continue #nothing\n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked 3/22/20; still need to check sold out case\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#California Carnivores\\nURL = 'https://www.californiacarnivores.com/'\\npage = urlopen(URL)\\nsoup = BeautifulSoup(page,'html.parser')\\nsoup = soup.find('ul',attrs={'class':'sidebar-module__list'})\\nlinks = soup.findAll('a')\\nlinks = [links[i] for i in range(len(links)) if i not in (0,1,3,13,16,22,26,30,31,32,33,34,35,36,37)]\\n#exluding following pages: plant collections (0), easy to grow (1), drosera (3), sarracenia (13),\\n#nepenthes (16), pinguicula (22), utricularia (26), waterwheel, ..., gifts (30-37)\\n\\nfor link in links:\\n    #Create URL2 to be URL of species type\\n    path = link['href']\\n    URL2 = URL + path\\n    \\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n    \\n    page_next = True\\n    while page_next:\\n        page = urlopen(URL2)\\n        soup = BeautifulSoup(page,'html.parser')\\n        containers = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half'})\\n        containers_sale = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half on-sale'})\\n\\n        #grabs information of normal items\\n        for container in containers:\\n            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\\n            specie = check_species(name)\\n\\n            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip()\\n            separate_index = price.find('$') #look for 1st instance of $\\n            price = price[separate_index+2:] #remove the all characters before and including the string '$ '\\n    \\n            names = names + [name]\\n            prices = prices + [price]\\n            saleprices = saleprices + ['']\\n            stores = stores + ['California Carnivores']\\n            soldouts = soldouts + ['']\\n            species = species + [specie]\\n        \\n        #grabs information of sale items\\n        for container in containers_sale:\\n            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\\n            specie = check_species(name)\\n\\n            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip() #price of items on sale should be of form '$ xx.xx\\n$ xx.xx'\\n            separate_index = price.rfind('$') #from end of string, look for 1st instance of $\\n            price_before = price[separate_index:] #gets original price\\n            price_before = price_before[2:] #remove the first 2 characters of the string '$ '\\n            price_after = price[:separate_index] #gets sale price\\n            price_after = price_after[2:] #remove the first 2 characters of the string '$ '\\n            price_after = price_after[:-1] #remove the last 2 characters of the string '$ '\\n    \\n            names = names + [name]\\n            prices = prices + [price_before]\\n            saleprices = saleprices + [price_after]\\n            stores = stores + ['California Carnivores']\\n            soldouts = soldouts + ['']\\n            species = species + [specie]\\n        \\n        #Updates the URL for next page; stops the while loop if there is no next page\\n        try:\\n            path = soup.find('a',attrs={'title':'Next »'})\\n            path = path['href']\\n            URL2 = URL + path\\n        except TypeError:\\n            page_next = False\\n        \\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True)\\ndf1\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked 3/22/20; still need to check sold out case\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#California Carnivores\n",
    "URL = 'https://www.californiacarnivores.com/'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "soup = soup.find('ul',attrs={'class':'sidebar-module__list'})\n",
    "links = soup.findAll('a')\n",
    "links = [links[i] for i in range(len(links)) if i not in (0,1,3,13,16,22,26,30,31,32,33,34,35,36,37)]\n",
    "#exluding following pages: plant collections (0), easy to grow (1), drosera (3), sarracenia (13),\n",
    "#nepenthes (16), pinguicula (22), utricularia (26), waterwheel, ..., gifts (30-37)\n",
    "\n",
    "for link in links:\n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half'})\n",
    "        containers_sale = soup.findAll('div',attrs={'class':'grid__item large--one-quarter medium-down--one-half on-sale'})\n",
    "\n",
    "        #grabs information of normal items\n",
    "        for container in containers:\n",
    "            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip()\n",
    "            separate_index = price.find('$') #look for 1st instance of $\n",
    "            price = price[separate_index+2:] #remove the all characters before and including the string '$ '\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            saleprices = saleprices + ['']\n",
    "            stores = stores + ['California Carnivores']\n",
    "            soldouts = soldouts + ['']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #grabs information of sale items\n",
    "        for container in containers_sale:\n",
    "            name = container.find('p',attrs={'class':'grid-link__title'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('p',attrs={'class':'grid-link__meta'}).text.strip() #price of items on sale should be of form '$ xx.xx\\n$ xx.xx'\n",
    "            separate_index = price.rfind('$') #from end of string, look for 1st instance of $\n",
    "            price_before = price[separate_index:] #gets original price\n",
    "            price_before = price_before[2:] #remove the first 2 characters of the string '$ '\n",
    "            price_after = price[:separate_index] #gets sale price\n",
    "            price_after = price_after[2:] #remove the first 2 characters of the string '$ '\n",
    "            price_after = price_after[:-1] #remove the last 2 characters of the string '$ '\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price_before]\n",
    "            saleprices = saleprices + [price_after]\n",
    "            stores = stores + ['California Carnivores']\n",
    "            soldouts = soldouts + ['']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            path = soup.find('a',attrs={'title':'Next »'})\n",
    "            path = path['href']\n",
    "            URL2 = URL + path\n",
    "        except TypeError:\n",
    "            page_next = False\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked 3/22/20; still need to check sold out case\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Cook's Carnivorous Plants\\nURL = 'http://www.flytraps.com/Scripts/'\\npage = urlopen(URL)\\nsoup = BeautifulSoup(page,'html.parser')\\nlinks = soup.findAll('span',attrs={'class':'CPcatDescProd'})\\nlinks = links[:25] #from aldrovanda to nepenthes hybrid lowland\\n\\nfor link in links:\\n    #Checks what type of species\\n    kind = link.text\\n    specie = check_species(kind)\\n        \\n    #Create URL2 to be URL of species type\\n    path = link.a['href']\\n    URL2 = URL + path\\n    \\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n    \\n    page = urlopen(URL2)\\n    soup = BeautifulSoup(page,'html.parser')\\n    containers = soup.findAll('div',attrs={'class':'prod-classic'})\\n    containers_count = len(containers)\\n    \\n    #print(URL2)\\n    #If is not blank, scrapes info. otherwise skips page\\n    if containers_count != 0:\\n        \\n        #each page contains 15 items, goes to next page when page_next mod 15 == 0\\n        page_next = 0\\n        while page_next % 15 == 0:\\n            page = urlopen(URL2)\\n            soup = BeautifulSoup(page,'html.parser')\\n            containers = soup.findAll('div',attrs={'class':'prod-classic'})\\n    \\n            for container in containers:\\n                name = container.h3.text.strip()\\n            \\n                #Most items on site are on sale. Try to process items as if the were on sale. If not on sale, then exception\\n                try:\\n                    price = container.find('del',attrs={'class':'CPprodLPriceV'}).text.strip()\\n                    price = price[1:] #removed '$' at beginning\\n            \\n                    saleprice = container.find('span',attrs={'class':'price'}).text.strip()\\n                    separate_index = saleprice.find('$') #look for 1st instance of $\\n                    saleprice = saleprice[separate_index+1:] #remove the all characters before and including the string '$'\\n                    saleprice = saleprice[:-3] #remove ' ea' from end of sales price\\n                except AttributeError:\\n                    price = container.find('span',attrs={'class':'price'}).text.strip()\\n                    separate_index = price.find('$') #look for 1st instance of $\\n                    price = price[separate_index+1:] #remove the all characters before and including the string '$'\\n                    price = price[:-3] #remove ' ea' from end of sales price\\n                \\n                    saleprice = ''\\n            \\n                names = names + [name]\\n                prices = prices + [price]\\n                stores = stores + ['Cook's Carnivorous Plants']\\n                soldouts = soldouts + ['']\\n                species = species + [specie]\\n                saleprices = saleprices + [saleprice]\\n                page_next = page_next + 1\\n                \\n            #Updates the URL for next page; stops the while loop if there is no next page\\n            if page_next % 15 == 0:\\n                paths = soup.find('div',attrs={'class':'spacing fl-right'})\\n                paths = paths.findAll('a')\\n                path = paths[len(paths)-1]['href'] #href of the last link (should be next page)\\n                URL2 = URL + path\\n        \\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True)\\ndf1\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked 3/22/20; still need to check sold out case\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Cook's Carnivorous Plants\n",
    "URL = 'http://www.flytraps.com/Scripts/'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('span',attrs={'class':'CPcatDescProd'})\n",
    "links = links[:25] #from aldrovanda to nepenthes hybrid lowland\n",
    "\n",
    "for link in links:\n",
    "    #Checks what type of species\n",
    "    kind = link.text\n",
    "    specie = check_species(kind)\n",
    "        \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.a['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    containers = soup.findAll('div',attrs={'class':'prod-classic'})\n",
    "    containers_count = len(containers)\n",
    "    \n",
    "    #print(URL2)\n",
    "    #If is not blank, scrapes info. otherwise skips page\n",
    "    if containers_count != 0:\n",
    "        \n",
    "        #each page contains 15 items, goes to next page when page_next mod 15 == 0\n",
    "        page_next = 0\n",
    "        while page_next % 15 == 0:\n",
    "            page = urlopen(URL2)\n",
    "            soup = BeautifulSoup(page,'html.parser')\n",
    "            containers = soup.findAll('div',attrs={'class':'prod-classic'})\n",
    "    \n",
    "            for container in containers:\n",
    "                name = container.h3.text.strip()\n",
    "            \n",
    "                #Most items on site are on sale. Try to process items as if the were on sale. If not on sale, then exception\n",
    "                try:\n",
    "                    price = container.find('del',attrs={'class':'CPprodLPriceV'}).text.strip()\n",
    "                    price = price[1:] #removed '$' at beginning\n",
    "            \n",
    "                    saleprice = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    separate_index = saleprice.find('$') #look for 1st instance of $\n",
    "                    saleprice = saleprice[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                    saleprice = saleprice[:-3] #remove ' ea' from end of sales price\n",
    "                except AttributeError:\n",
    "                    price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    separate_index = price.find('$') #look for 1st instance of $\n",
    "                    price = price[separate_index+1:] #remove the all characters before and including the string '$'\n",
    "                    price = price[:-3] #remove ' ea' from end of sales price\n",
    "                \n",
    "                    saleprice = ''\n",
    "            \n",
    "                names = names + [name]\n",
    "                prices = prices + [price]\n",
    "                stores = stores + ['Cook\\'s Carnivorous Plants']\n",
    "                soldouts = soldouts + ['']\n",
    "                species = species + [specie]\n",
    "                saleprices = saleprices + [saleprice]\n",
    "                page_next = page_next + 1\n",
    "                \n",
    "            #Updates the URL for next page; stops the while loop if there is no next page\n",
    "            if page_next % 15 == 0:\n",
    "                paths = soup.find('div',attrs={'class':'spacing fl-right'})\n",
    "                paths = paths.findAll('a')\n",
    "                path = paths[len(paths)-1]['href'] #href of the last link (should be next page)\n",
    "                URL2 = URL + path\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked 3/22/20\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Carnivero\\nURL = 'https://www.carnivero.com'\\npage = urlopen(URL)\\nsoup = BeautifulSoup(page,'html.parser')\\nlinks = soup.findAll('div',attrs={'class':'grid__item small--one-half medium-up--one-fifth slide-up-animation animated'})\\nlinks = [links[i] for i in range(10) if i!=1]  #all categories except beginner plants\\n\\n#Looks at plant categories page\\nfor link in links:            \\n    #Create URL2 to be URL of species type\\n    path = link.a['href']\\n    URL2 = URL + path\\n    \\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n  \\n    page_next = True\\n    while page_next:\\n        page = urlopen(URL2)\\n        soup = BeautifulSoup(page,'html.parser')\\n        containers = soup.findAll('div',attrs={'class':'product grid__item medium-up--one-third small--one-half slide-up-animation animated'})\\n    \\n        for container in containers:\\n            name = container.find('div',attrs={'class':'product__title text-center'}).text.strip()\\n            specie = check_species(name)\\n\\n            try:\\n                price = container.find('span',attrs={'class':'product__price'}).text.strip()\\n                separate_index = price.find('$')+1 #look for 1st instance of $\\n                price = price[separate_index:] #remove the all characters before and including the string '$'\\n                prices = prices + [price]\\n                saleprices = saleprices + ['']           \\n            except AttributeError:\\n                #grab original price\\n                price = container.find('s').text.strip()\\n                separate_index = price.find('$')+1 #look for 1st instance of $\\n                price = price[separate_index:] #remove the all characters before and including the string '$'\\n                prices = prices + [price]\\n            \\n                #grab new sales price\\n                price = container.find('span',attrs={'class':'product__price--on-sale'}).text.strip()\\n                separate_index = price.find('$')+1 #look for 1st instance of $\\n                price = price[separate_index:] #remove the all characters before and including the string '$'\\n                saleprices = saleprices + [price] \\n            \\n            try:\\n                soldout = container.find('strong',attrs={'class':'sold-out-text'}).text.strip()\\n                soldouts = soldouts + [soldout.lower()]\\n            except AttributeError:\\n                soldouts = soldouts + ['']\\n            \\n            names = names + [name]\\n            stores = stores + ['Carnivero']\\n            species = species + [specie]\\n        \\n        #Updates the URL for next page; stops the while loop if there is no next page\\n        try:\\n            path = soup.find('span',attrs={'class':'next'})\\n            path = path.a['href']\\n            URL2 = 'https://www.carnivero.com' + path\\n        except AttributeError:\\n            page_next = False\\n        \\n        \\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True)\\ndf1\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked 3/22/20\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Carnivero\n",
    "URL = 'https://www.carnivero.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('div',attrs={'class':'grid__item small--one-half medium-up--one-fifth slide-up-animation animated'})\n",
    "links = [links[i] for i in range(10) if i!=1]  #all categories except beginner plants\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:            \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.a['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "  \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        page = urlopen(URL2)\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        containers = soup.findAll('div',attrs={'class':'product grid__item medium-up--one-third small--one-half slide-up-animation animated'})\n",
    "    \n",
    "        for container in containers:\n",
    "            name = container.find('div',attrs={'class':'product__title text-center'}).text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            try:\n",
    "                price = container.find('span',attrs={'class':'product__price'}).text.strip()\n",
    "                separate_index = price.find('$')+1 #look for 1st instance of $\n",
    "                price = price[separate_index:] #remove the all characters before and including the string '$'\n",
    "                prices = prices + [price]\n",
    "                saleprices = saleprices + ['']           \n",
    "            except AttributeError:\n",
    "                #grab original price\n",
    "                price = container.find('s').text.strip()\n",
    "                separate_index = price.find('$')+1 #look for 1st instance of $\n",
    "                price = price[separate_index:] #remove the all characters before and including the string '$'\n",
    "                prices = prices + [price]\n",
    "            \n",
    "                #grab new sales price\n",
    "                price = container.find('span',attrs={'class':'product__price--on-sale'}).text.strip()\n",
    "                separate_index = price.find('$')+1 #look for 1st instance of $\n",
    "                price = price[separate_index:] #remove the all characters before and including the string '$'\n",
    "                saleprices = saleprices + [price] \n",
    "            \n",
    "            try:\n",
    "                soldout = container.find('strong',attrs={'class':'sold-out-text'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "            \n",
    "            names = names + [name]\n",
    "            stores = stores + ['Carnivero']\n",
    "            species = species + [specie]\n",
    "        \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            path = soup.find('span',attrs={'class':'next'})\n",
    "            path = path.a['href']\n",
    "            URL2 = 'https://www.carnivero.com' + path\n",
    "        except AttributeError:\n",
    "            page_next = False\n",
    "        \n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked 3/22/20\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Native Exotics\\nURL = 'https://nativeexoticsonline.com'\\nh = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\\nreq = Request(URL,headers=h) \\npage = urlopen(req).read() \\nsoup = BeautifulSoup(page,'html.parser')\\nlinks = soup.find('ul',attrs={'class':'dropdown'})\\nlinks = links.findAll('a')\\npages_of_interest = [5] + list(range(10,15)) #All Neps + Cephs,Drosera,..., Utrics\\nlinks = [links[i] for i in pages_of_interest]\\n\\n#Looks at plant categories page\\nfor link in links:      \\n    #Create URL2 to be URL of species type\\n    path = link['href']\\n    URL2 = URL + path\\n    \\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n    \\n    page_next = True\\n    while page_next:\\n        req = Request(URL2,headers=h) \\n        page = urlopen(req).read() \\n        soup = BeautifulSoup(page,'html.parser')\\n        container_big = soup.find('ul',attrs={'class':'products columns-4'})\\n        containers = container_big.findAll('li')\\n    \\n        for container in containers:\\n            name = container.find('h2').text.strip()\\n            specie = check_species(name)\\n        \\n            price_list = container.findAll('span',attrs={'class':'woocommerce-Price-amount amount'})\\n            #2 prices listed when on sale. 1st list element is original price, 2nd element is sales price\\n            if len(price_list) == 2:\\n                price = price_list[0].text.strip()\\n                price = price[2:]\\n                saleprice = price_list[1].text.strip()\\n                saleprice = saleprice[2:]             \\n            elif len(price_list) == 1:\\n                price = price_list[0].text.strip()\\n                price = price[2:]\\n                saleprice = ''\\n        \\n            try:\\n                soldout = container.find('span',attrs={'class':'soldout'}).text.strip()\\n                soldouts = soldouts + [soldout.lower()]\\n            except AttributeError:\\n                soldouts = soldouts + ['']\\n            \\n            names = names + [name]\\n            prices = prices + [price]\\n            stores = stores + ['Native Exotics']\\n            saleprices = saleprices + [saleprice]\\n            species = species + [specie]\\n            \\n        #Updates the URL for next page; stops the while loop if there is no next page\\n        try:\\n            URL2 = soup.find('a',attrs={'class':'next page-numbers'})\\n            URL2 = URL2['href']\\n        except TypeError:\\n            page_next = False\\n        \\n        \\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True)\\ndf1\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked 3/22/20\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Native Exotics\n",
    "URL = 'https://nativeexoticsonline.com'\n",
    "h = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "req = Request(URL,headers=h) \n",
    "page = urlopen(req).read() \n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.find('ul',attrs={'class':'dropdown'})\n",
    "links = links.findAll('a')\n",
    "pages_of_interest = [5] + list(range(10,15)) #All Neps + Cephs,Drosera,..., Utrics\n",
    "links = [links[i] for i in pages_of_interest]\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:      \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link['href']\n",
    "    URL2 = URL + path\n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page_next = True\n",
    "    while page_next:\n",
    "        req = Request(URL2,headers=h) \n",
    "        page = urlopen(req).read() \n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "        container_big = soup.find('ul',attrs={'class':'products columns-4'})\n",
    "        containers = container_big.findAll('li')\n",
    "    \n",
    "        for container in containers:\n",
    "            name = container.find('h2').text.strip()\n",
    "            specie = check_species(name)\n",
    "        \n",
    "            price_list = container.findAll('span',attrs={'class':'woocommerce-Price-amount amount'})\n",
    "            #2 prices listed when on sale. 1st list element is original price, 2nd element is sales price\n",
    "            if len(price_list) == 2:\n",
    "                price = price_list[0].text.strip()\n",
    "                price = price[2:]\n",
    "                saleprice = price_list[1].text.strip()\n",
    "                saleprice = saleprice[2:]             \n",
    "            elif len(price_list) == 1:\n",
    "                price = price_list[0].text.strip()\n",
    "                price = price[2:]\n",
    "                saleprice = ''\n",
    "        \n",
    "            try:\n",
    "                soldout = container.find('span',attrs={'class':'soldout'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "            \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Native Exotics']\n",
    "            saleprices = saleprices + [saleprice]\n",
    "            species = species + [specie]\n",
    "            \n",
    "        #Updates the URL for next page; stops the while loop if there is no next page\n",
    "        try:\n",
    "            URL2 = soup.find('a',attrs={'class':'next page-numbers'})\n",
    "            URL2 = URL2['href']\n",
    "        except TypeError:\n",
    "            page_next = False\n",
    "        \n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked: 3/22/20\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Carnivorous Plant Nursery\\nURL = 'https://carnivorousplantnursery.com'\\npage = urlopen(URL)\\nsoup = BeautifulSoup(page,'html.parser')\\nlinks = soup.findAll('article')\\nlinks = links[:9] #Only looks at VFT to buterworts\\n\\n#Looks at plant categories page\\nfor link in links:      \\n    #Create URL2 to be URL of species type\\n    path = link.find('figure')\\n    path = path.a['href']\\n    URL2 = URL + path   \\n    \\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n    \\n    page = urlopen(URL2)\\n    soup = BeautifulSoup(page,'html.parser')\\n    containers = soup.findAll('article',attrs={'class':'productgrid--item imagestyle--cropped-small '})\\n    for container in containers:\\n        name = container.find('h2').text.strip()\\n        specie = check_species(name)\\n    \\n        price = container.find('div',attrs={'class':'price--main'}).text.strip()\\n        separate_index = price.find('$')+1 #look for 1st instance of $\\n        price = price[separate_index:] #remove the all characters before and including the string '$'\\n    \\n        names = names + [name]\\n        prices = prices + [price]\\n        stores = stores + ['Carnivorous Plant Nursery']\\n        saleprices = saleprices + [''] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!change when on sale\\n        species = species + [specie]\\n        \\n        #looks for sold out items\\n        try:\\n            soldout = container.find('span',attrs={'class':'productitem--badge badge--soldout'}).text.strip()\\n            soldouts = soldouts + [soldout.lower()]\\n        except AttributeError:\\n            soldouts = soldouts + ['']\\n            \\n\\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True) \\ndf1\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked: 3/22/20\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Carnivorous Plant Nursery\n",
    "URL = 'https://carnivorousplantnursery.com'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "links = soup.findAll('article')\n",
    "links = links[:9] #Only looks at VFT to buterworts\n",
    "\n",
    "#Looks at plant categories page\n",
    "for link in links:      \n",
    "    #Create URL2 to be URL of species type\n",
    "    path = link.find('figure')\n",
    "    path = path.a['href']\n",
    "    URL2 = URL + path   \n",
    "    \n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "    \n",
    "    page = urlopen(URL2)\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    containers = soup.findAll('article',attrs={'class':'productgrid--item imagestyle--cropped-small '})\n",
    "    for container in containers:\n",
    "        name = container.find('h2').text.strip()\n",
    "        specie = check_species(name)\n",
    "    \n",
    "        price = container.find('div',attrs={'class':'price--main'}).text.strip()\n",
    "        separate_index = price.find('$')+1 #look for 1st instance of $\n",
    "        price = price[separate_index:] #remove the all characters before and including the string '$'\n",
    "    \n",
    "        names = names + [name]\n",
    "        prices = prices + [price]\n",
    "        stores = stores + ['Carnivorous Plant Nursery']\n",
    "        saleprices = saleprices + [''] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!change when on sale\n",
    "        species = species + [specie]\n",
    "        \n",
    "        #looks for sold out items\n",
    "        try:\n",
    "            soldout = container.find('span',attrs={'class':'productitem--badge badge--soldout'}).text.strip()\n",
    "            soldouts = soldouts + [soldout.lower()]\n",
    "        except AttributeError:\n",
    "            soldouts = soldouts + ['']\n",
    "            \n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True) \n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked: 3/22/20\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Bergen Water Gardens\\n#cannot extract next page button functionality; cannot extract how many pages total\\n#instead keeps going to next page until error\\ntry:\\n    page_number = 1\\n    while page_number < 16:\\n        URL = 'https://bergenwatergardens.com/product-category/carnivorous-plants/?fwp_paged=%d' % page_number\\n        h = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\\n        req = Request(URL,headers=h) \\n        page = urlopen(req).read() \\n        soup = BeautifulSoup(page,'html.parser')\\n    \\n        #wait random time between 0-5 seconds before scraping data\\n        r = random.randint(0,5)\\n        time.sleep(r)\\n        \\n        containers = soup.find('ul',attrs={'class':'products columns-4'})\\n        containers = containers.findAll('li')        \\n        \\n        for container in containers:\\n            name = container.find('h2').text.strip()\\n            specie = check_species(name)\\n\\n            price = container.find('span',attrs={'class':'price'}).text.strip()\\n            #if item is on sale, gets normal price and sale price\\n            try:\\n                container.find('span',attrs={'class':'onsale'}).text.strip() == 'Sale!'\\n    \\n                separate_index = price.find('$')+2 #from BEGINNING of string, look for 1st instance of $\\n                separate_index2 = price.find(' ') #from BEGINNING of string, look for 1st instance of space\\n                price_before = price[separate_index:separate_index2] #gets original price\\n        \\n                separate_index = price.rfind('$')+2 #from END of string, look for 1st instance of $\\n                price_after = price[separate_index:] #gets sale price\\n    \\n                price = price_before\\n                saleprice = price_after\\n            #else just get the normal price\\n            except AttributeError:\\n                if price.rfind('$') != 0: #cases when prices is a range like $X.XX - $X.XX\\n                    price = container.find('span',attrs={'class':'price'}).text.strip()\\n                    separate_index = price.find('$')+2 #from BEGINNING of string, look for 1st instance of $\\n                    separate_index2 = price.find(' ') #from BEGINNING of string, look for 1st instance of space before -\\n                    price = price[separate_index:separate_index2] #remove everything except price\\n                    saleprice = ''\\n                else:\\n                    price = container.find('span',attrs={'class':'price'}).text.strip()\\n                    price = price[2:] #removes '$ ' before price\\n                    saleprice = ''\\n    \\n            names = names + [name]\\n            prices = prices + [price]\\n            stores = stores + ['Bergen Water Gardens']\\n            saleprices = saleprices + [saleprice]\\n            species = species + [specie]        \\n        \\n            #looks for sold out items\\n            try:\\n                URL2 = container.a['href']\\n                req = Request(URL2,headers=h) \\n                page = urlopen(req).read() \\n                soup = BeautifulSoup(page,'html.parser')\\n                \\n                soldout = soup.find('p',attrs={'class':'stock out-of-stock'}).text.strip()\\n                soldouts = soldouts + [soldout.lower()]\\n            except AttributeError:\\n                soldouts = soldouts + ['']\\n                        \\n        #increase page_number for while loop\\n        page_number = page_number + 1\\n#if container is empty, pass- does nothing, 'pass' in python instead of 'continue'\\nexcept (AttributeError,IndexError):\\n    pass \\n    \\n\\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True) \\ndf1\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked: 3/22/20\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Bergen Water Gardens\n",
    "#cannot extract next page button functionality; cannot extract how many pages total\n",
    "#instead keeps going to next page until error\n",
    "try:\n",
    "    page_number = 1\n",
    "    while page_number < 16:\n",
    "        URL = 'https://bergenwatergardens.com/product-category/carnivorous-plants/?fwp_paged=%d' % page_number\n",
    "        h = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "        req = Request(URL,headers=h) \n",
    "        page = urlopen(req).read() \n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "    \n",
    "        #wait random time between 0-5 seconds before scraping data\n",
    "        r = random.randint(0,5)\n",
    "        time.sleep(r)\n",
    "        \n",
    "        containers = soup.find('ul',attrs={'class':'products columns-4'})\n",
    "        containers = containers.findAll('li')        \n",
    "        \n",
    "        for container in containers:\n",
    "            name = container.find('h2').text.strip()\n",
    "            specie = check_species(name)\n",
    "\n",
    "            price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "            #if item is on sale, gets normal price and sale price\n",
    "            try:\n",
    "                container.find('span',attrs={'class':'onsale'}).text.strip() == 'Sale!'\n",
    "    \n",
    "                separate_index = price.find('$')+2 #from BEGINNING of string, look for 1st instance of $\n",
    "                separate_index2 = price.find(' ') #from BEGINNING of string, look for 1st instance of space\n",
    "                price_before = price[separate_index:separate_index2] #gets original price\n",
    "        \n",
    "                separate_index = price.rfind('$')+2 #from END of string, look for 1st instance of $\n",
    "                price_after = price[separate_index:] #gets sale price\n",
    "    \n",
    "                price = price_before\n",
    "                saleprice = price_after\n",
    "            #else just get the normal price\n",
    "            except AttributeError:\n",
    "                if price.rfind('$') != 0: #cases when prices is a range like $X.XX - $X.XX\n",
    "                    price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    separate_index = price.find('$')+2 #from BEGINNING of string, look for 1st instance of $\n",
    "                    separate_index2 = price.find(' ') #from BEGINNING of string, look for 1st instance of space before -\n",
    "                    price = price[separate_index:separate_index2] #remove everything except price\n",
    "                    saleprice = ''\n",
    "                else:\n",
    "                    price = container.find('span',attrs={'class':'price'}).text.strip()\n",
    "                    price = price[2:] #removes '$ ' before price\n",
    "                    saleprice = ''\n",
    "    \n",
    "            names = names + [name]\n",
    "            prices = prices + [price]\n",
    "            stores = stores + ['Bergen Water Gardens']\n",
    "            saleprices = saleprices + [saleprice]\n",
    "            species = species + [specie]        \n",
    "        \n",
    "            #looks for sold out items\n",
    "            try:\n",
    "                URL2 = container.a['href']\n",
    "                req = Request(URL2,headers=h) \n",
    "                page = urlopen(req).read() \n",
    "                soup = BeautifulSoup(page,'html.parser')\n",
    "                \n",
    "                soldout = soup.find('p',attrs={'class':'stock out-of-stock'}).text.strip()\n",
    "                soldouts = soldouts + [soldout.lower()]\n",
    "            except AttributeError:\n",
    "                soldouts = soldouts + ['']\n",
    "                        \n",
    "        #increase page_number for while loop\n",
    "        page_number = page_number + 1\n",
    "#if container is empty, pass- does nothing, 'pass' in python instead of 'continue'\n",
    "except (AttributeError,IndexError):\n",
    "    pass \n",
    "    \n",
    "\n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True) \n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#last checked: 3/22/20; still need to check sold out case\\nnames = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\\n\\n#Petflytrap\\n#cannot extract next page button functionality; cannot extract how many pages total\\n#instead, manually provide page numbers to for-loop over\\nfor page_number in range(1,16):\\n    URL = 'https://www.petflytrap.com/All-carnivorous-plants_c_11-%d-3.html' % page_number\\n    h = {'User-Agent':'Mozilla/5.0'}\\n    req = Request(URL,headers=h) \\n    page = urlopen(req).read()\\n    soup = BeautifulSoup(page,'html.parser')\\n\\n    #wait random time between 0-5 seconds before scraping data\\n    r = random.randint(0,5)\\n    time.sleep(r)\\n\\n    containers = soup.find('div',attrs={'class':'product-items product-items-4'})\\n\\n    for i in range(len(containers.findAll('div',attrs={'class':'name'}))):\\n        name = containers.findAll('div',attrs={'class':'name'})[i].text.strip()\\n        specie = check_species(name)\\n    \\n        price = containers.findAll('div',attrs={'class':'price'})[i].text.strip()\\n        #if item is on sale, seperate into price_before and price_after\\n        if price.rfind('$') != 0:\\n            separate_index = price.find('$')+1 #from BEGINNING of string, look for 1st instance of $\\n            separate_index2 = price.find('\\n') #from BEGINNING of string, look for 1st instance of \\n\\n            price_before = price[separate_index:separate_index2] #remove everything except price\\n        \\n            separate_index = price.rfind('$')+1 #from END of string, look for 1st instance of $\\n            separate_index2 = price.rfind('\\n') #from END of string, look for 1st instance of \\n\\n            price_after = price[separate_index:separate_index2] #remove everything except price\\n        else:\\n            price_before = price[1:] #removes '$' before price\\n            price_after = ''        \\n\\n\\n        names = names + [name]\\n        prices = prices + [price_before]\\n        saleprices = saleprices + [price_after]\\n        stores = stores + ['Petflytap']\\n        soldouts = soldouts + ['']\\n        species = species + [specie]\\n\\n        \\nd = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\\ndf1 = pd.DataFrame(d)\\ndf = df.append(df1,ignore_index=True)\\ndf1\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#last checked: 3/22/20; still need to check sold out case\n",
    "names = []; prices = []; saleprices = []; soldouts = []; stores = []; species = []\n",
    "\n",
    "#Petflytrap\n",
    "#cannot extract next page button functionality; cannot extract how many pages total\n",
    "#instead, manually provide page numbers to for-loop over\n",
    "for page_number in range(1,16):\n",
    "    URL = 'https://www.petflytrap.com/All-carnivorous-plants_c_11-%d-3.html' % page_number\n",
    "    h = {'User-Agent':'Mozilla/5.0'}\n",
    "    req = Request(URL,headers=h) \n",
    "    page = urlopen(req).read()\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "\n",
    "    #wait random time between 0-5 seconds before scraping data\n",
    "    r = random.randint(0,5)\n",
    "    time.sleep(r)\n",
    "\n",
    "    containers = soup.find('div',attrs={'class':'product-items product-items-4'})\n",
    "\n",
    "    for i in range(len(containers.findAll('div',attrs={'class':'name'}))):\n",
    "        name = containers.findAll('div',attrs={'class':'name'})[i].text.strip()\n",
    "        specie = check_species(name)\n",
    "    \n",
    "        price = containers.findAll('div',attrs={'class':'price'})[i].text.strip()\n",
    "        #if item is on sale, seperate into price_before and price_after\n",
    "        if price.rfind('$') != 0:\n",
    "            separate_index = price.find('$')+1 #from BEGINNING of string, look for 1st instance of $\n",
    "            separate_index2 = price.find('\\n') #from BEGINNING of string, look for 1st instance of \\n\n",
    "            price_before = price[separate_index:separate_index2] #remove everything except price\n",
    "        \n",
    "            separate_index = price.rfind('$')+1 #from END of string, look for 1st instance of $\n",
    "            separate_index2 = price.rfind('\\n') #from END of string, look for 1st instance of \\n\n",
    "            price_after = price[separate_index:separate_index2] #remove everything except price\n",
    "        else:\n",
    "            price_before = price[1:] #removes '$' before price\n",
    "            price_after = ''        \n",
    "\n",
    "\n",
    "        names = names + [name]\n",
    "        prices = prices + [price_before]\n",
    "        saleprices = saleprices + [price_after]\n",
    "        stores = stores + ['Petflytap']\n",
    "        soldouts = soldouts + ['']\n",
    "        species = species + [specie]\n",
    "\n",
    "        \n",
    "d = {'Name':names,'Price':prices,'Sale Price':saleprices,'Sold Out':soldouts,'Store':stores,'Species':species}\n",
    "df1 = pd.DataFrame(d)\n",
    "df = df.append(df1,ignore_index=True)\n",
    "df1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Predatory Plants\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Predatory Plants\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72+ Hour Heat Pack - For shipping with plants</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepenthes ventricosa \"Red\"</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spagmoss 100 gram briquette</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nepenthes copelandii BE-3046</td>\n",
       "      <td>19.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nepenthes veitchii x platychila BE-3213</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nepenthes aristolochioides x ventricosa BE-3447</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nepenthes burkei BE-3254</td>\n",
       "      <td>18.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nepenthes spathulata x spectablilis BE-3314 *S...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nepenthes albomarginata BE-3004</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nepenthes jacquelineae (G. Gadang) BE-3092</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nepenthes ventricosa x glandulifera BE-3401</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nepenthes singalana x burkei BE-3878</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nepenthes ramispina x robcantleyi BE-3939</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nepenthes fusca BE-3465 (Mamut Copper Mine)</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x fusc...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nepenthes mollis (hurrelliana AW)</td>\n",
       "      <td>239.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nepenthes x trusmadiensis (AW Clone 2) *ONLY 1...</td>\n",
       "      <td>139.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nepenthes muluensis x lowii BE-3128</td>\n",
       "      <td>59.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nepenthes bongso BE-3036</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nepenthes flava BE-3652</td>\n",
       "      <td>69.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nepenthes burbidgeae x talangensis BE-3952</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nepenthes truncata x spectabilis MT *LARGE SIZE*</td>\n",
       "      <td>65.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nepenthes glandulifera x veitchii BE-3689 *SEE...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nepenthes eustachya x tenuis BE-3971</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nepenthes burbidgeae x aristolochioides BE-3784</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nepenthes klossii BE-3452</td>\n",
       "      <td>329.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nepenthes spathulata x (burbidgeae x edwardsia...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nepenthes spathulata x veitchii BE-3648</td>\n",
       "      <td>19.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nepenthes burbidgeae x sibuyanensis BE-3885</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>Sarracenia leucophylla 'Titan'</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>Sarracenia Lover's Set</td>\n",
       "      <td>39.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>Sarracenia 'MardiGras'</td>\n",
       "      <td>12.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>Sarracenia minor</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Sarracenia purpurea</td>\n",
       "      <td>7.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>Sarracenia purpurea subspecies venosa</td>\n",
       "      <td>6.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>Sarracenia readii x moorei</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>Sarracenia 'Scarlet Belle'</td>\n",
       "      <td>6.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>Sarracenia x excellens (LEUCOPHYLLA X MINOR)</td>\n",
       "      <td>11.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>Venus Flytrap 6-plant ULTIMATE COLLECTOR'S Set</td>\n",
       "      <td>139.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>Venus Flytrap 'Alien' - NEW CULTIVAR with WICK...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>Venus Flytrap 'B-52' - RARE COLLECTOR'S PLANT ...</td>\n",
       "      <td>16.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Venus Flytrap 'Bristletooth' - Like a saw blade!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Venus Flytrap COLLECTOR'S Set - RARE and UNUSU...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>Venus Flytrap 'Coquillage' - NEW CULTIVAR with...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Venus Flytrap 'DC XL' - some of the largest tr...</td>\n",
       "      <td>25.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>Venus Flytrap 'Dente' - Jagged teeth!</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>Venus Flytrap 'Dutch' - Classic!</td>\n",
       "      <td>11.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>Venus Flytrap 'Fine Tooth x Red' - Collector's...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>Venus Flytrap 'Ginormous' - RARE COLLECTOR'S P...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Venus Flytrap 'Green Dragon' - RARELY AVAILABLE!</td>\n",
       "      <td>15.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>Venus Flytrap 'Leo Songs Jaws' - NEW LOWER PRICE!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>13.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>Venus Flytrap 'Lips and Lashes' - ULTRA-RARE, ...</td>\n",
       "      <td>34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>Venus Flytrap 'Martahs Lips'- ULTRA-RARE, and ...</td>\n",
       "      <td>34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>Venus Flytrap 'Megatraps' - HUGE TRAPS, and RA...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>Venus Flytrap 'Royal Red' - NEW LOWER PRICE!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>Venus Flytrap 'Trichterfalle' - NEW CULTIVAR!!</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>Venus Flytrap 'Typical'</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>Venus Flytrap 'UK Sawtooth' - RARE - ONLY A FE...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>Venus Flytrap 'Werewolf' - WICKED CLAWS!</td>\n",
       "      <td>21.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2604 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name   Price  Sale Price  \\\n",
       "0         72+ Hour Heat Pack - For shipping with plants    4.00         NaN   \n",
       "1                            Nepenthes ventricosa \"Red\"   10.00         NaN   \n",
       "2     Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...  149.00         NaN   \n",
       "3                           Spagmoss 100 gram briquette    7.00         NaN   \n",
       "4                          Nepenthes copelandii BE-3046   19.00         NaN   \n",
       "5               Nepenthes veitchii x platychila BE-3213   29.00         NaN   \n",
       "6       Nepenthes aristolochioides x ventricosa BE-3447   14.00         NaN   \n",
       "7                              Nepenthes burkei BE-3254   18.00         NaN   \n",
       "8     Nepenthes spathulata x spectablilis BE-3314 *S...   15.00         NaN   \n",
       "9                       Nepenthes albomarginata BE-3004   29.00         NaN   \n",
       "10           Nepenthes jacquelineae (G. Gadang) BE-3092   49.00         NaN   \n",
       "11          Nepenthes ventricosa x glandulifera BE-3401   14.00         NaN   \n",
       "12                 Nepenthes singalana x burkei BE-3878   14.00         NaN   \n",
       "13            Nepenthes ramispina x robcantleyi BE-3939   24.00         NaN   \n",
       "14          Nepenthes fusca BE-3465 (Mamut Copper Mine)   16.00         NaN   \n",
       "15    Nepenthes robcantleyi \"Queen of Hearts\" x fusc...   24.00         NaN   \n",
       "16                    Nepenthes mollis (hurrelliana AW)  239.00         NaN   \n",
       "17    Nepenthes x trusmadiensis (AW Clone 2) *ONLY 1...  139.00         NaN   \n",
       "18                  Nepenthes muluensis x lowii BE-3128   59.00         NaN   \n",
       "19                             Nepenthes bongso BE-3036   39.00         NaN   \n",
       "20                              Nepenthes flava BE-3652   69.00         NaN   \n",
       "21           Nepenthes burbidgeae x talangensis BE-3952   29.00         NaN   \n",
       "22     Nepenthes truncata x spectabilis MT *LARGE SIZE*   65.00         NaN   \n",
       "23    Nepenthes glandulifera x veitchii BE-3689 *SEE...   22.00         NaN   \n",
       "24                 Nepenthes eustachya x tenuis BE-3971   22.00         NaN   \n",
       "25      Nepenthes burbidgeae x aristolochioides BE-3784   29.00         NaN   \n",
       "26                            Nepenthes klossii BE-3452  329.00      299.00   \n",
       "27    Nepenthes spathulata x (burbidgeae x edwardsia...   39.00         NaN   \n",
       "28              Nepenthes spathulata x veitchii BE-3648   19.00         NaN   \n",
       "29          Nepenthes burbidgeae x sibuyanensis BE-3885   29.00         NaN   \n",
       "...                                                 ...     ...         ...   \n",
       "2574                     Sarracenia leucophylla 'Titan'   10.99         NaN   \n",
       "2575                             Sarracenia Lover's Set   39.99         NaN   \n",
       "2576                             Sarracenia 'MardiGras'   12.99         NaN   \n",
       "2577                                   Sarracenia minor    8.99         NaN   \n",
       "2578                                Sarracenia purpurea    7.99         NaN   \n",
       "2579              Sarracenia purpurea subspecies venosa    6.99         NaN   \n",
       "2580                         Sarracenia readii x moorei   10.99         NaN   \n",
       "2581                         Sarracenia 'Scarlet Belle'    6.99         NaN   \n",
       "2582       Sarracenia x excellens (LEUCOPHYLLA X MINOR)   11.99         NaN   \n",
       "2583     Venus Flytrap 6-plant ULTIMATE COLLECTOR'S Set  139.99         NaN   \n",
       "2584  Venus Flytrap 'Alien' - NEW CULTIVAR with WICK...   39.99         NaN   \n",
       "2585  Venus Flytrap 'B-52' - RARE COLLECTOR'S PLANT ...   16.99         NaN   \n",
       "2586   Venus Flytrap 'Bristletooth' - Like a saw blade!   14.99         NaN   \n",
       "2587  Venus Flytrap COLLECTOR'S Set - RARE and UNUSU...   69.99         NaN   \n",
       "2588  Venus Flytrap 'Coquillage' - NEW CULTIVAR with...   19.99         NaN   \n",
       "2589  Venus Flytrap 'DC XL' - some of the largest tr...   25.99         NaN   \n",
       "2590              Venus Flytrap 'Dente' - Jagged teeth!    8.99         NaN   \n",
       "2591                   Venus Flytrap 'Dutch' - Classic!   11.99         NaN   \n",
       "2592  Venus Flytrap 'Fine Tooth x Red' - Collector's...   18.99         NaN   \n",
       "2593  Venus Flytrap 'Ginormous' - RARE COLLECTOR'S P...   17.99         NaN   \n",
       "2594   Venus Flytrap 'Green Dragon' - RARELY AVAILABLE!   15.99         NaN   \n",
       "2595  Venus Flytrap 'Leo Songs Jaws' - NEW LOWER PRICE!   14.99       13.99   \n",
       "2596  Venus Flytrap 'Lips and Lashes' - ULTRA-RARE, ...   34.99         NaN   \n",
       "2597  Venus Flytrap 'Martahs Lips'- ULTRA-RARE, and ...   34.99         NaN   \n",
       "2598  Venus Flytrap 'Megatraps' - HUGE TRAPS, and RA...   24.99         NaN   \n",
       "2599       Venus Flytrap 'Royal Red' - NEW LOWER PRICE!   14.99         NaN   \n",
       "2600     Venus Flytrap 'Trichterfalle' - NEW CULTIVAR!!   19.99         NaN   \n",
       "2601                            Venus Flytrap 'Typical'    8.99         NaN   \n",
       "2602  Venus Flytrap 'UK Sawtooth' - RARE - ONLY A FE...   18.99         NaN   \n",
       "2603           Venus Flytrap 'Werewolf' - WICKED CLAWS!   21.99         NaN   \n",
       "\n",
       "      Sold Out                Store            Species  \n",
       "0          NaN  Pearl River Exotics              other  \n",
       "1          NaN  Pearl River Exotics          nepenthes  \n",
       "2          NaN  Pearl River Exotics          nepenthes  \n",
       "3          NaN  Pearl River Exotics              other  \n",
       "4          NaN  Pearl River Exotics          nepenthes  \n",
       "5          NaN  Pearl River Exotics          nepenthes  \n",
       "6          NaN  Pearl River Exotics          nepenthes  \n",
       "7     sold out  Pearl River Exotics          nepenthes  \n",
       "8          NaN  Pearl River Exotics          nepenthes  \n",
       "9          NaN  Pearl River Exotics          nepenthes  \n",
       "10         NaN  Pearl River Exotics          nepenthes  \n",
       "11         NaN  Pearl River Exotics          nepenthes  \n",
       "12         NaN  Pearl River Exotics          nepenthes  \n",
       "13         NaN  Pearl River Exotics          nepenthes  \n",
       "14         NaN  Pearl River Exotics          nepenthes  \n",
       "15         NaN  Pearl River Exotics          nepenthes  \n",
       "16         NaN  Pearl River Exotics          nepenthes  \n",
       "17    sold out  Pearl River Exotics          nepenthes  \n",
       "18         NaN  Pearl River Exotics          nepenthes  \n",
       "19         NaN  Pearl River Exotics          nepenthes  \n",
       "20         NaN  Pearl River Exotics          nepenthes  \n",
       "21         NaN  Pearl River Exotics          nepenthes  \n",
       "22         NaN  Pearl River Exotics          nepenthes  \n",
       "23         NaN  Pearl River Exotics          nepenthes  \n",
       "24         NaN  Pearl River Exotics          nepenthes  \n",
       "25         NaN  Pearl River Exotics          nepenthes  \n",
       "26         NaN  Pearl River Exotics          nepenthes  \n",
       "27         NaN  Pearl River Exotics          nepenthes  \n",
       "28         NaN  Pearl River Exotics          nepenthes  \n",
       "29         NaN  Pearl River Exotics          nepenthes  \n",
       "...        ...                  ...                ...  \n",
       "2574       NaN            Petflytap         sarracenia  \n",
       "2575       NaN            Petflytap         sarracenia  \n",
       "2576       NaN            Petflytap         sarracenia  \n",
       "2577       NaN            Petflytap         sarracenia  \n",
       "2578       NaN            Petflytap         sarracenia  \n",
       "2579       NaN            Petflytap         sarracenia  \n",
       "2580       NaN            Petflytap         sarracenia  \n",
       "2581       NaN            Petflytap         sarracenia  \n",
       "2582       NaN            Petflytap         sarracenia  \n",
       "2583       NaN            Petflytap  dionaea muscipula  \n",
       "2584       NaN            Petflytap  dionaea muscipula  \n",
       "2585       NaN            Petflytap  dionaea muscipula  \n",
       "2586       NaN            Petflytap  dionaea muscipula  \n",
       "2587       NaN            Petflytap  dionaea muscipula  \n",
       "2588       NaN            Petflytap  dionaea muscipula  \n",
       "2589       NaN            Petflytap  dionaea muscipula  \n",
       "2590       NaN            Petflytap  dionaea muscipula  \n",
       "2591       NaN            Petflytap  dionaea muscipula  \n",
       "2592       NaN            Petflytap  dionaea muscipula  \n",
       "2593       NaN            Petflytap  dionaea muscipula  \n",
       "2594       NaN            Petflytap  dionaea muscipula  \n",
       "2595       NaN            Petflytap  dionaea muscipula  \n",
       "2596       NaN            Petflytap  dionaea muscipula  \n",
       "2597       NaN            Petflytap  dionaea muscipula  \n",
       "2598       NaN            Petflytap  dionaea muscipula  \n",
       "2599       NaN            Petflytap  dionaea muscipula  \n",
       "2600       NaN            Petflytap  dionaea muscipula  \n",
       "2601       NaN            Petflytap  dionaea muscipula  \n",
       "2602       NaN            Petflytap  dionaea muscipula  \n",
       "2603       NaN            Petflytap  dionaea muscipula  \n",
       "\n",
       "[2604 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Export concatinated df to Excel\n",
    "date = '2020_03_28' #date format 2020_01_01\n",
    "file_name_1 = 'df_%s.xlsx' % date\n",
    "#df.to_excel(file_name_1)\n",
    "\n",
    "\n",
    "#Converting exported df back into correct format\n",
    "df = pd.read_excel(file_name_1)\n",
    "#df = df.drop(columns='Unnamed: 0') #removing column of indecies\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the complete database is compiled, apply tagging function - tags any species found in product\n",
    "#https://www.carnivorousplants.co.uk/resources/nepenthes-interactive-guide/\n",
    "#https://en.wikipedia.org/wiki/List_of_Nepenthes_species\n",
    "#https://en.wikipedia.org/wiki/List_of_Utricularia_species\n",
    "\n",
    "#compare product to database of species known\n",
    "#if str in database, then species = str\n",
    "df['Cross1'] = ''\n",
    "df['Cross2'] = ''\n",
    "df['Cross3'] = ''\n",
    "df['Cross4'] = ''\n",
    "df['Cross5'] = ''\n",
    "df['Cross6'] = ''\n",
    "df['Cross7'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 175\n",
    "name_nepenthes = [''] * n\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Nepenthes_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('tr')\n",
    "\n",
    "for i in range(1,n):\n",
    "    container = containers[i]\n",
    "    name = container.find('a')\n",
    "    name_nepenthes[i] = name['title'][10:] #removing 'Nepenthes ' from string\n",
    "    \n",
    "name_nepenthes = name_nepenthes[1:] #remove header row\n",
    "\n",
    "#lady = lady luck, bill = bill bailey\n",
    "name_nepenthes_hybrids = ['lady','hookeriana','suki','bill','diana','briggsiana','rokko','ventrata', \\\n",
    "                          'miranda','trusmadiensis','gentle']\n",
    "name_nepenthes_hybrids_cross = [['ventricosa','ampullaria'],['ampullaria','rafflesiana'], \\\n",
    "                                ['rafflesiana','sibuyanensis'],['ventricosa','singalana'], \\\n",
    "                                ['ventricosa','sibuyanensis','ampullaria'],['ventricosa','lowii'], \\\n",
    "                                ['maxima','thorelii'],['ventricosa','alata'],['maxima','northiana'], \\\n",
    "                                ['lowii','macrophylla'],['fusca','maxima']]\n",
    "\n",
    "#name_nepenthes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 198\n",
    "name_drosera = [''] * n\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Drosera_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('tr')\n",
    "\n",
    "for i in range(1,n):\n",
    "    container = containers[i]\n",
    "    try:\n",
    "        name = container.a.text.strip()\n",
    "        index = name.find('\\xa0')+1 #look for 1st instance of '\\xa0'\n",
    "        name_drosera[i] = name[index:]\n",
    "    except AttributeError:\n",
    "        name = container.i.text.strip()\n",
    "        index = name.find(' ')+1 #look for 1st instance of space\n",
    "        name_drosera[i] = name[index:]\n",
    "        \n",
    "    \n",
    "name_drosera = name_drosera[2:] #remove header rows\n",
    "\n",
    "#pink = dork's pink, marston = Marston Dragon, sunset = California Sunset, butterfly = Butterfly Valley, \n",
    "#\n",
    "name_drosera_hybrids = ['hercules','pink','dichotoma','multifida','marston','sunset','butterfly','andromeda', \\\n",
    "                        'indumenta','tracyii','dilatopetiolaris']\n",
    "name_drosera_hybrids_cross = [['capensis','aliciae'],['callistos','lasiantha'],['binata'],['binata'],['binata'], \\\n",
    "                              ['filiformis'],['intermedia','filiformis'],['schizandra','prolifera'],['macrantha'], \\\n",
    "                              ['filiformis'],['dilatato–petiolaris']]\n",
    "\n",
    "#name_drosera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_utricularia = []\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Utricularia_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('ul')\n",
    "\n",
    "#scraping species names from containers[4] to containers[39]\n",
    "for i in range(4,40):\n",
    "    container = containers[i]\n",
    "    string_names = container.text.replace('Utricularia ','').split('\\n') #removing 'Utricularia ' from string\n",
    "\n",
    "    #Cleaning up Cross names\n",
    "    for j in range(len(string_names)):\n",
    "        #Removing Footnotes [1]\n",
    "        if '[' in string_names[j]:\n",
    "            index = string_names[j].find('[')\n",
    "            string_names[j] = string_names[j][:(index-1)]\n",
    "\n",
    "            \n",
    "    name_utricularia = name_utricularia + string_names\n",
    "\n",
    "    \n",
    "##have not found a natural hybrid yet; no need for this section yet\n",
    "#name_utricularia_hybrids = ['lady','hookeriana','suki','bill','diana','briggsiana','rokko','ventrata', \\\n",
    "#                          'miranda','trusmadiensis']\n",
    "#name_utricularia_hybrids_cross = [['ventricosa','ampullaria'],['ampullaria','rafflesiana'], \\\n",
    "#                                ['rafflesiana','sibuyanensis'],['ventricosa','singalana'], \\\n",
    "#                                ['ventricosa','sibuyanensis','ampullaria'],['ventricosa','lowii'], \\\n",
    "#                                ['maxima','thorelii'],['ventricosa','alata'],['maxima','northiana'], \\\n",
    "#                                ['lowii','macrophylla']]\n",
    "\n",
    "#name_utricularia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_pinguicula = []\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_Pinguicula_species'\n",
    "page = urlopen(URL)\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "containers = soup.findAll('ul')\n",
    "\n",
    "\n",
    "#scraping species names from containers[4] to containers[26]\n",
    "for i in range(4,27):\n",
    "    container = containers[i]\n",
    "    string_names = container.text.replace('Pinguicula ','').split('\\n') #removing 'Pinguicula ' from string\n",
    "    \n",
    "    #Cleaning up Cross names\n",
    "    for j in range(len(string_names)):\n",
    "        #Removing text after -\n",
    "        if '–' in string_names[j]:\n",
    "            index = string_names[j].find('–')\n",
    "            string_names[j] = string_names[j][:(index-1)]\n",
    "        #Removing Footnotes [1]\n",
    "        elif '[' in string_names[j]:\n",
    "            index = string_names[j].find('[')\n",
    "            string_names[j] = string_names[j][:(index-1)]\n",
    "            \n",
    "            \n",
    "    name_pinguicula = name_pinguicula + string_names\n",
    "    \n",
    "\n",
    "#john = john rizzi, alfred = alfred lau, \n",
    "name_pinguicula_hybrids = ['sethos','weser','john','nivalis','alfred','florian','gina','apasionada']\n",
    "name_pinguicula_hybrids_cross = [['ehlersiae','moranensis'],['moranensis','ehlersiae'],['moranensis','?'],['nivalis'], \\\n",
    "                                 ['gigantea','?'],['debbertiana','esseriana'],['zecheri','agnata'],['gigantea','moctezumae']]\n",
    "\n",
    "#name_pinguicula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sold Out</th>\n",
       "      <th>Store</th>\n",
       "      <th>Species</th>\n",
       "      <th>Cross1</th>\n",
       "      <th>Cross2</th>\n",
       "      <th>Cross3</th>\n",
       "      <th>Cross4</th>\n",
       "      <th>Cross5</th>\n",
       "      <th>Cross6</th>\n",
       "      <th>Cross7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72+ Hour Heat Pack - For shipping with plants</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepenthes ventricosa \"Red\"</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>ventricosa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>robcantleyi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spagmoss 100 gram briquette</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nepenthes copelandii BE-3046</td>\n",
       "      <td>19.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>copelandii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nepenthes veitchii x platychila BE-3213</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>veitchii</td>\n",
       "      <td>platychila</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nepenthes aristolochioides x ventricosa BE-3447</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>aristolochioides</td>\n",
       "      <td>ventricosa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nepenthes burkei BE-3254</td>\n",
       "      <td>18.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>burkei</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nepenthes spathulata x spectablilis BE-3314 *S...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>spathulata</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nepenthes albomarginata BE-3004</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>albomarginata</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nepenthes jacquelineae (G. Gadang) BE-3092</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>jacquelineae</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nepenthes ventricosa x glandulifera BE-3401</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>ventricosa</td>\n",
       "      <td>glandulifera</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nepenthes singalana x burkei BE-3878</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>singalana</td>\n",
       "      <td>burkei</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nepenthes ramispina x robcantleyi BE-3939</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>ramispina</td>\n",
       "      <td>robcantleyi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nepenthes fusca BE-3465 (Mamut Copper Mine)</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>fusca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nepenthes robcantleyi \"Queen of Hearts\" x fusc...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>robcantleyi</td>\n",
       "      <td>fusca</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nepenthes mollis (hurrelliana AW)</td>\n",
       "      <td>239.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>mollis</td>\n",
       "      <td>hurrelliana</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nepenthes x trusmadiensis (AW Clone 2) *ONLY 1...</td>\n",
       "      <td>139.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold out</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>lowii</td>\n",
       "      <td>macrophylla</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nepenthes muluensis x lowii BE-3128</td>\n",
       "      <td>59.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>muluensis</td>\n",
       "      <td>lowii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nepenthes bongso BE-3036</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>bongso</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nepenthes flava BE-3652</td>\n",
       "      <td>69.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>flava</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nepenthes burbidgeae x talangensis BE-3952</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>burbidgeae</td>\n",
       "      <td>talangensis</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nepenthes truncata x spectabilis MT *LARGE SIZE*</td>\n",
       "      <td>65.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>truncata</td>\n",
       "      <td>spectabilis</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nepenthes glandulifera x veitchii BE-3689 *SEE...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>glandulifera</td>\n",
       "      <td>veitchii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nepenthes eustachya x tenuis BE-3971</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>eustachya</td>\n",
       "      <td>tenuis</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nepenthes burbidgeae x aristolochioides BE-3784</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>burbidgeae</td>\n",
       "      <td>aristolochioides</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nepenthes klossii BE-3452</td>\n",
       "      <td>329.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>klossii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nepenthes spathulata x (burbidgeae x edwardsia...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>spathulata</td>\n",
       "      <td>burbidgeae</td>\n",
       "      <td>edwardsiana</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nepenthes spathulata x veitchii BE-3648</td>\n",
       "      <td>19.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>spathulata</td>\n",
       "      <td>veitchii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nepenthes burbidgeae x sibuyanensis BE-3885</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl River Exotics</td>\n",
       "      <td>nepenthes</td>\n",
       "      <td>burbidgeae</td>\n",
       "      <td>sibuyanensis</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>Sarracenia leucophylla 'Titan'</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>Sarracenia Lover's Set</td>\n",
       "      <td>39.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>Sarracenia 'MardiGras'</td>\n",
       "      <td>12.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>Sarracenia minor</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Sarracenia purpurea</td>\n",
       "      <td>7.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>Sarracenia purpurea subspecies venosa</td>\n",
       "      <td>6.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>Sarracenia readii x moorei</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>Sarracenia 'Scarlet Belle'</td>\n",
       "      <td>6.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>Sarracenia x excellens (LEUCOPHYLLA X MINOR)</td>\n",
       "      <td>11.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>sarracenia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>Venus Flytrap 6-plant ULTIMATE COLLECTOR'S Set</td>\n",
       "      <td>139.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>Venus Flytrap 'Alien' - NEW CULTIVAR with WICK...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>Venus Flytrap 'B-52' - RARE COLLECTOR'S PLANT ...</td>\n",
       "      <td>16.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Venus Flytrap 'Bristletooth' - Like a saw blade!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Venus Flytrap COLLECTOR'S Set - RARE and UNUSU...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>Venus Flytrap 'Coquillage' - NEW CULTIVAR with...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Venus Flytrap 'DC XL' - some of the largest tr...</td>\n",
       "      <td>25.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>Venus Flytrap 'Dente' - Jagged teeth!</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>Venus Flytrap 'Dutch' - Classic!</td>\n",
       "      <td>11.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>Venus Flytrap 'Fine Tooth x Red' - Collector's...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>Venus Flytrap 'Ginormous' - RARE COLLECTOR'S P...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Venus Flytrap 'Green Dragon' - RARELY AVAILABLE!</td>\n",
       "      <td>15.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>Venus Flytrap 'Leo Songs Jaws' - NEW LOWER PRICE!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>13.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>Venus Flytrap 'Lips and Lashes' - ULTRA-RARE, ...</td>\n",
       "      <td>34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>Venus Flytrap 'Martahs Lips'- ULTRA-RARE, and ...</td>\n",
       "      <td>34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>Venus Flytrap 'Megatraps' - HUGE TRAPS, and RA...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>Venus Flytrap 'Royal Red' - NEW LOWER PRICE!</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>Venus Flytrap 'Trichterfalle' - NEW CULTIVAR!!</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>Venus Flytrap 'Typical'</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>Venus Flytrap 'UK Sawtooth' - RARE - ONLY A FE...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>Venus Flytrap 'Werewolf' - WICKED CLAWS!</td>\n",
       "      <td>21.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petflytap</td>\n",
       "      <td>dionaea muscipula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name   Price  Sale Price  \\\n",
       "0         72+ Hour Heat Pack - For shipping with plants    4.00         NaN   \n",
       "1                            Nepenthes ventricosa \"Red\"   10.00         NaN   \n",
       "2     Nepenthes robcantleyi \"Queen of Hearts\" x \"Kin...  149.00         NaN   \n",
       "3                           Spagmoss 100 gram briquette    7.00         NaN   \n",
       "4                          Nepenthes copelandii BE-3046   19.00         NaN   \n",
       "5               Nepenthes veitchii x platychila BE-3213   29.00         NaN   \n",
       "6       Nepenthes aristolochioides x ventricosa BE-3447   14.00         NaN   \n",
       "7                              Nepenthes burkei BE-3254   18.00         NaN   \n",
       "8     Nepenthes spathulata x spectablilis BE-3314 *S...   15.00         NaN   \n",
       "9                       Nepenthes albomarginata BE-3004   29.00         NaN   \n",
       "10           Nepenthes jacquelineae (G. Gadang) BE-3092   49.00         NaN   \n",
       "11          Nepenthes ventricosa x glandulifera BE-3401   14.00         NaN   \n",
       "12                 Nepenthes singalana x burkei BE-3878   14.00         NaN   \n",
       "13            Nepenthes ramispina x robcantleyi BE-3939   24.00         NaN   \n",
       "14          Nepenthes fusca BE-3465 (Mamut Copper Mine)   16.00         NaN   \n",
       "15    Nepenthes robcantleyi \"Queen of Hearts\" x fusc...   24.00         NaN   \n",
       "16                    Nepenthes mollis (hurrelliana AW)  239.00         NaN   \n",
       "17    Nepenthes x trusmadiensis (AW Clone 2) *ONLY 1...  139.00         NaN   \n",
       "18                  Nepenthes muluensis x lowii BE-3128   59.00         NaN   \n",
       "19                             Nepenthes bongso BE-3036   39.00         NaN   \n",
       "20                              Nepenthes flava BE-3652   69.00         NaN   \n",
       "21           Nepenthes burbidgeae x talangensis BE-3952   29.00         NaN   \n",
       "22     Nepenthes truncata x spectabilis MT *LARGE SIZE*   65.00         NaN   \n",
       "23    Nepenthes glandulifera x veitchii BE-3689 *SEE...   22.00         NaN   \n",
       "24                 Nepenthes eustachya x tenuis BE-3971   22.00         NaN   \n",
       "25      Nepenthes burbidgeae x aristolochioides BE-3784   29.00         NaN   \n",
       "26                            Nepenthes klossii BE-3452  329.00      299.00   \n",
       "27    Nepenthes spathulata x (burbidgeae x edwardsia...   39.00         NaN   \n",
       "28              Nepenthes spathulata x veitchii BE-3648   19.00         NaN   \n",
       "29          Nepenthes burbidgeae x sibuyanensis BE-3885   29.00         NaN   \n",
       "...                                                 ...     ...         ...   \n",
       "2574                     Sarracenia leucophylla 'Titan'   10.99         NaN   \n",
       "2575                             Sarracenia Lover's Set   39.99         NaN   \n",
       "2576                             Sarracenia 'MardiGras'   12.99         NaN   \n",
       "2577                                   Sarracenia minor    8.99         NaN   \n",
       "2578                                Sarracenia purpurea    7.99         NaN   \n",
       "2579              Sarracenia purpurea subspecies venosa    6.99         NaN   \n",
       "2580                         Sarracenia readii x moorei   10.99         NaN   \n",
       "2581                         Sarracenia 'Scarlet Belle'    6.99         NaN   \n",
       "2582       Sarracenia x excellens (LEUCOPHYLLA X MINOR)   11.99         NaN   \n",
       "2583     Venus Flytrap 6-plant ULTIMATE COLLECTOR'S Set  139.99         NaN   \n",
       "2584  Venus Flytrap 'Alien' - NEW CULTIVAR with WICK...   39.99         NaN   \n",
       "2585  Venus Flytrap 'B-52' - RARE COLLECTOR'S PLANT ...   16.99         NaN   \n",
       "2586   Venus Flytrap 'Bristletooth' - Like a saw blade!   14.99         NaN   \n",
       "2587  Venus Flytrap COLLECTOR'S Set - RARE and UNUSU...   69.99         NaN   \n",
       "2588  Venus Flytrap 'Coquillage' - NEW CULTIVAR with...   19.99         NaN   \n",
       "2589  Venus Flytrap 'DC XL' - some of the largest tr...   25.99         NaN   \n",
       "2590              Venus Flytrap 'Dente' - Jagged teeth!    8.99         NaN   \n",
       "2591                   Venus Flytrap 'Dutch' - Classic!   11.99         NaN   \n",
       "2592  Venus Flytrap 'Fine Tooth x Red' - Collector's...   18.99         NaN   \n",
       "2593  Venus Flytrap 'Ginormous' - RARE COLLECTOR'S P...   17.99         NaN   \n",
       "2594   Venus Flytrap 'Green Dragon' - RARELY AVAILABLE!   15.99         NaN   \n",
       "2595  Venus Flytrap 'Leo Songs Jaws' - NEW LOWER PRICE!   14.99       13.99   \n",
       "2596  Venus Flytrap 'Lips and Lashes' - ULTRA-RARE, ...   34.99         NaN   \n",
       "2597  Venus Flytrap 'Martahs Lips'- ULTRA-RARE, and ...   34.99         NaN   \n",
       "2598  Venus Flytrap 'Megatraps' - HUGE TRAPS, and RA...   24.99         NaN   \n",
       "2599       Venus Flytrap 'Royal Red' - NEW LOWER PRICE!   14.99         NaN   \n",
       "2600     Venus Flytrap 'Trichterfalle' - NEW CULTIVAR!!   19.99         NaN   \n",
       "2601                            Venus Flytrap 'Typical'    8.99         NaN   \n",
       "2602  Venus Flytrap 'UK Sawtooth' - RARE - ONLY A FE...   18.99         NaN   \n",
       "2603           Venus Flytrap 'Werewolf' - WICKED CLAWS!   21.99         NaN   \n",
       "\n",
       "      Sold Out                Store            Species            Cross1  \\\n",
       "0          NaN  Pearl River Exotics              other                     \n",
       "1          NaN  Pearl River Exotics          nepenthes        ventricosa   \n",
       "2          NaN  Pearl River Exotics          nepenthes       robcantleyi   \n",
       "3          NaN  Pearl River Exotics              other                     \n",
       "4          NaN  Pearl River Exotics          nepenthes        copelandii   \n",
       "5          NaN  Pearl River Exotics          nepenthes          veitchii   \n",
       "6          NaN  Pearl River Exotics          nepenthes  aristolochioides   \n",
       "7     sold out  Pearl River Exotics          nepenthes            burkei   \n",
       "8          NaN  Pearl River Exotics          nepenthes        spathulata   \n",
       "9          NaN  Pearl River Exotics          nepenthes     albomarginata   \n",
       "10         NaN  Pearl River Exotics          nepenthes      jacquelineae   \n",
       "11         NaN  Pearl River Exotics          nepenthes        ventricosa   \n",
       "12         NaN  Pearl River Exotics          nepenthes         singalana   \n",
       "13         NaN  Pearl River Exotics          nepenthes         ramispina   \n",
       "14         NaN  Pearl River Exotics          nepenthes             fusca   \n",
       "15         NaN  Pearl River Exotics          nepenthes       robcantleyi   \n",
       "16         NaN  Pearl River Exotics          nepenthes            mollis   \n",
       "17    sold out  Pearl River Exotics          nepenthes             lowii   \n",
       "18         NaN  Pearl River Exotics          nepenthes         muluensis   \n",
       "19         NaN  Pearl River Exotics          nepenthes            bongso   \n",
       "20         NaN  Pearl River Exotics          nepenthes             flava   \n",
       "21         NaN  Pearl River Exotics          nepenthes        burbidgeae   \n",
       "22         NaN  Pearl River Exotics          nepenthes          truncata   \n",
       "23         NaN  Pearl River Exotics          nepenthes      glandulifera   \n",
       "24         NaN  Pearl River Exotics          nepenthes         eustachya   \n",
       "25         NaN  Pearl River Exotics          nepenthes        burbidgeae   \n",
       "26         NaN  Pearl River Exotics          nepenthes           klossii   \n",
       "27         NaN  Pearl River Exotics          nepenthes        spathulata   \n",
       "28         NaN  Pearl River Exotics          nepenthes        spathulata   \n",
       "29         NaN  Pearl River Exotics          nepenthes        burbidgeae   \n",
       "...        ...                  ...                ...               ...   \n",
       "2574       NaN            Petflytap         sarracenia                     \n",
       "2575       NaN            Petflytap         sarracenia                     \n",
       "2576       NaN            Petflytap         sarracenia                     \n",
       "2577       NaN            Petflytap         sarracenia                     \n",
       "2578       NaN            Petflytap         sarracenia                     \n",
       "2579       NaN            Petflytap         sarracenia                     \n",
       "2580       NaN            Petflytap         sarracenia                     \n",
       "2581       NaN            Petflytap         sarracenia                     \n",
       "2582       NaN            Petflytap         sarracenia                     \n",
       "2583       NaN            Petflytap  dionaea muscipula                     \n",
       "2584       NaN            Petflytap  dionaea muscipula                     \n",
       "2585       NaN            Petflytap  dionaea muscipula                     \n",
       "2586       NaN            Petflytap  dionaea muscipula                     \n",
       "2587       NaN            Petflytap  dionaea muscipula                     \n",
       "2588       NaN            Petflytap  dionaea muscipula                     \n",
       "2589       NaN            Petflytap  dionaea muscipula                     \n",
       "2590       NaN            Petflytap  dionaea muscipula                     \n",
       "2591       NaN            Petflytap  dionaea muscipula                     \n",
       "2592       NaN            Petflytap  dionaea muscipula                     \n",
       "2593       NaN            Petflytap  dionaea muscipula                     \n",
       "2594       NaN            Petflytap  dionaea muscipula                     \n",
       "2595       NaN            Petflytap  dionaea muscipula                     \n",
       "2596       NaN            Petflytap  dionaea muscipula                     \n",
       "2597       NaN            Petflytap  dionaea muscipula                     \n",
       "2598       NaN            Petflytap  dionaea muscipula                     \n",
       "2599       NaN            Petflytap  dionaea muscipula                     \n",
       "2600       NaN            Petflytap  dionaea muscipula                     \n",
       "2601       NaN            Petflytap  dionaea muscipula                     \n",
       "2602       NaN            Petflytap  dionaea muscipula                     \n",
       "2603       NaN            Petflytap  dionaea muscipula                     \n",
       "\n",
       "                Cross2       Cross3 Cross4 Cross5 Cross6 Cross7  \n",
       "0                                                                \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "5           platychila                                           \n",
       "6           ventricosa                                           \n",
       "7                                                                \n",
       "8                                                                \n",
       "9                                                                \n",
       "10                                                               \n",
       "11        glandulifera                                           \n",
       "12              burkei                                           \n",
       "13         robcantleyi                                           \n",
       "14                                                               \n",
       "15               fusca                                           \n",
       "16         hurrelliana                                           \n",
       "17         macrophylla                                           \n",
       "18               lowii                                           \n",
       "19                                                               \n",
       "20                                                               \n",
       "21         talangensis                                           \n",
       "22         spectabilis                                           \n",
       "23            veitchii                                           \n",
       "24              tenuis                                           \n",
       "25    aristolochioides                                           \n",
       "26                                                               \n",
       "27          burbidgeae  edwardsiana                              \n",
       "28            veitchii                                           \n",
       "29        sibuyanensis                                           \n",
       "...                ...          ...    ...    ...    ...    ...  \n",
       "2574                                                             \n",
       "2575                                                             \n",
       "2576                                                             \n",
       "2577                                                             \n",
       "2578                                                             \n",
       "2579                                                             \n",
       "2580                                                             \n",
       "2581                                                             \n",
       "2582                                                             \n",
       "2583                                                             \n",
       "2584                                                             \n",
       "2585                                                             \n",
       "2586                                                             \n",
       "2587                                                             \n",
       "2588                                                             \n",
       "2589                                                             \n",
       "2590                                                             \n",
       "2591                                                             \n",
       "2592                                                             \n",
       "2593                                                             \n",
       "2594                                                             \n",
       "2595                                                             \n",
       "2596                                                             \n",
       "2597                                                             \n",
       "2598                                                             \n",
       "2599                                                             \n",
       "2600                                                             \n",
       "2601                                                             \n",
       "2602                                                             \n",
       "2603                                                             \n",
       "\n",
       "[2604 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i is row index, j is column index\n",
    "#len(df) gives number of rows in df\n",
    "for i in range(len(df)):\n",
    "    #removing all of the special characters:()[] so the string is split into 'ventricosa' and not '(ventricosa''\n",
    "    string_split = df.at[i,'Name'].replace('(','').replace(')','').replace('[','').replace(']','').replace(',','')\n",
    "    string_split = string_split.replace('-','').replace('–','').replace('\\'','').replace('\\\"','').replace('‘','')\n",
    "    string_split = string_split.replace('’','')\n",
    "    #convert entire string to lowercase\n",
    "    string_split = string_split.lower()\n",
    "    \n",
    "    #Filling in Cross columns\n",
    "    string_split = string_split.split(' ')\n",
    "    count = 1 #counter for column name\n",
    "    repeat_cross = []\n",
    "    \n",
    "    #If-Else If by species\n",
    "    if df.at[i,'Species'] == 'nepenthes':\n",
    "        for j in range(len(string_split)):\n",
    "            #if cross is in name_nepenthes and not repeated, add it to CrossX column\n",
    "            if (string_split[j] in name_nepenthes) and (string_split[j] not in repeat_cross):\n",
    "                column = 'Cross%d' % count\n",
    "                count = count + 1\n",
    "                df.loc[[i],[column]] = string_split[j]\n",
    "                repeat_cross = repeat_cross + [string_split[j]]\n",
    "            #if cross is in name_nepenthes_hybrid and not repeated, add it to CrossX column\n",
    "            elif (string_split[j] in name_nepenthes_hybrids) and (string_split[j] not in repeat_cross):\n",
    "                m = name_nepenthes_hybrids.index(string_split[j])\n",
    "                for k in range(len(name_nepenthes_hybrids_cross[m])):\n",
    "                    column = 'Cross%d' % count\n",
    "                    count = count + 1\n",
    "                    df.loc[[i],[column]] = name_nepenthes_hybrids_cross[m][k]\n",
    "                    repeat_cross = repeat_cross + [string_split[j]]\n",
    "                    repeat_cross = repeat_cross + [name_nepenthes_hybrids_cross[m][k]]\n",
    "    elif df.at[i,'Species'] == 'drosera':\n",
    "        for j in range(len(string_split)):\n",
    "            #if cross is in name_drosera and not repeated, add it to CrossX column\n",
    "            if (string_split[j] in name_drosera) and (string_split[j] not in repeat_cross):\n",
    "                column = 'Cross%d' % count\n",
    "                count = count + 1\n",
    "                df.loc[[i],[column]] = string_split[j]\n",
    "                repeat_cross = repeat_cross + [string_split[j]]\n",
    "            #if cross is in name_drosera_hybrid and not repeated, add it to CrossX column\n",
    "            elif (string_split[j] in name_drosera_hybrids) and (string_split[j] not in repeat_cross):\n",
    "                m = name_drosera_hybrids.index(string_split[j])\n",
    "                for k in range(len(name_drosera_hybrids_cross[m])):\n",
    "                    column = 'Cross%d' % count\n",
    "                    count = count + 1\n",
    "                    df.loc[[i],[column]] = name_drosera_hybrids_cross[m][k]\n",
    "                    repeat_cross = repeat_cross + [string_split[j]]\n",
    "                    repeat_cross = repeat_cross + [name_drosera_hybrids_cross[m][k]]\n",
    "    elif df.at[i,'Species'] == 'utricularia':\n",
    "        for j in range(len(string_split)):\n",
    "            #if cross is in name_utricularia and not repeated, add it to CrossX column\n",
    "            if (string_split[j] in name_utricularia) and (string_split[j] not in repeat_cross):\n",
    "                column = 'Cross%d' % count\n",
    "                count = count + 1\n",
    "                df.loc[[i],[column]] = string_split[j]\n",
    "                repeat_cross = repeat_cross + [string_split[j]]  \n",
    "    elif df.at[i,'Species'] == 'pinguicula':\n",
    "        for j in range(len(string_split)):\n",
    "            #if cross is in name_pinguicula and not repeated, add it to CrossX column\n",
    "            if (string_split[j] in name_pinguicula) and (string_split[j] not in repeat_cross):\n",
    "                column = 'Cross%d' % count\n",
    "                count = count + 1\n",
    "                df.loc[[i],[column]] = string_split[j]\n",
    "                repeat_cross = repeat_cross + [string_split[j]]\n",
    "            #if cross is in name_pinguicula_hybrid and not repeated, add it to CrossX column\n",
    "            elif (string_split[j] in name_pinguicula_hybrids) and (string_split[j] not in repeat_cross):\n",
    "                m = name_pinguicula_hybrids.index(string_split[j])\n",
    "                for k in range(len(name_pinguicula_hybrids_cross[m])):\n",
    "                    column = 'Cross%d' % count\n",
    "                    count = count + 1\n",
    "                    df.loc[[i],[column]] = name_pinguicula_hybrids_cross[m][k]\n",
    "                    repeat_cross = repeat_cross + [string_split[j]]\n",
    "                    repeat_cross = repeat_cross + [name_pinguicula_hybrids_cross[m][k]]\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "#create special if clause when tag is not found, open product page and scan description text for tags\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Check what does not have any Cross1 tag\\nfor i in range(len(df)):\\n    if (df.loc[i,'Cross1'] is '') and (df.loc[i,'Species'] == 'pinguicula'):\\n        print(i,df.loc[i,'Name'])\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Check what does not have any Cross1 tag\n",
    "for i in range(len(df)):\n",
    "    if (df.loc[i,'Cross1'] is '') and (df.loc[i,'Species'] == 'pinguicula'):\n",
    "        print(i,df.loc[i,'Name'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n#Converting exported df back into correct format\\ndf = pd.read_excel('dfCross_2020_02_05.xlsx')\\ndf = df.drop(columns='Unnamed: 0') #removing column of indecies\\n\\ndf\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Export df with Cross1, ... ,Cross6 to Excel\n",
    "file_name_2 = 'dfCross_%s.xlsx' % date\n",
    "df.to_excel(file_name_2)\n",
    "\n",
    "\n",
    "#Converting exported df back into correct format\n",
    "df = pd.read_excel('dfCross_2020_02_05.xlsx')\n",
    "df = df.drop(columns='Unnamed: 0') #removing column of indecies\n",
    "\n",
    "df\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
